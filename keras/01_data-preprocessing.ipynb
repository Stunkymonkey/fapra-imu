{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Importing matplotlib to plot images.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# for file-management\n",
    "import pickle as pkl\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Participant Infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = list(range(1, 21))\n",
    "smartphones = {\"N6\", \"N5X\", \"S4\", \"S3Mini\"}\n",
    "# TODO remove\n",
    "participants = list(range(42, 43))\n",
    "smartphones = {\"N5X\"}\n",
    "extension = 0\n",
    "\n",
    "sensors = {\n",
    "    \"acc\",\n",
    "    \"gyro\",\n",
    "    \"ori\",\n",
    "    \"grav\",\n",
    "    \"mag\",\n",
    "    \"rot\"\n",
    "}\n",
    "\n",
    "tasks = {\n",
    "    \"points\",\n",
    "    \"fitts\"\n",
    "}\n",
    "\n",
    "file_names = sensors.union(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: 42 N5X\n",
      "interval 1\n",
      "interval 2\n",
      "interval 3\n",
      "interval 4\n",
      "interval 5\n",
      "interval 6\n",
      "interval 7\n",
      "interval 8\n",
      "interval 9\n",
      "interval 10\n",
      "interval 11\n",
      "interval 12\n",
      "interval 13\n",
      "interval 14\n",
      "interval 15\n",
      "interval 16\n",
      "interval 17\n",
      "interval 18\n",
      "interval 19\n",
      "interval 20\n",
      "interval 21\n",
      "interval 22\n",
      "interval 23\n",
      "interval 24\n",
      "interval 25\n",
      "interval 26\n",
      "interval 27\n",
      "interval 28\n",
      "interval 29\n",
      "interval 30\n",
      "interval 31\n",
      "interval 32\n",
      "interval 33\n",
      "interval 34\n",
      "interval 35\n",
      "interval 36\n",
      "interval 37\n",
      "interval 38\n",
      "interval 39\n",
      "interval 40\n",
      "interval 41\n",
      "interval 42\n",
      "interval 43\n",
      "interval 44\n",
      "interval 45\n",
      "interval 46\n",
      "interval 47\n",
      "interval 48\n",
      "interval 49\n",
      "interval 50\n",
      "interval 51\n",
      "interval 52\n",
      "interval 53\n",
      "interval 54\n",
      "interval 55\n",
      "interval 56\n",
      "interval 57\n",
      "interval 58\n",
      "interval 59\n",
      "interval 60\n",
      "interval 61\n",
      "interval 62\n",
      "interval 63\n",
      "interval 64\n",
      "interval 65\n",
      "interval 66\n",
      "interval 67\n",
      "interval 68\n",
      "interval 69\n",
      "interval 70\n",
      "interval 71\n",
      "interval 72\n",
      "interval 73\n",
      "interval 74\n",
      "interval 75\n",
      "interval 76\n",
      "interval 77\n",
      "interval 78\n",
      "interval 79\n",
      "interval 80\n",
      "interval 81\n",
      "interval 82\n",
      "interval 83\n",
      "interval 84\n",
      "interval 85\n",
      "interval 86\n",
      "interval 87\n",
      "interval 88\n",
      "interval 89\n",
      "interval 90\n",
      "interval 91\n",
      "interval 92\n",
      "interval 93\n",
      "interval 94\n",
      "interval 95\n",
      "interval 96\n",
      "interval 97\n",
      "interval 98\n",
      "interval 99\n",
      "interval 100\n",
      "interval 101\n",
      "interval 102\n",
      "interval 103\n",
      "interval 104\n",
      "interval 105\n",
      "interval 106\n",
      "interval 107\n",
      "interval 108\n",
      "interval 109\n",
      "interval 110\n",
      "interval 111\n",
      "interval 112\n",
      "interval 113\n",
      "interval 114\n",
      "interval 115\n",
      "interval 116\n",
      "interval 117\n",
      "interval 118\n",
      "interval 119\n",
      "interval 120\n",
      "interval 121\n",
      "interval 122\n",
      "interval 123\n",
      "interval 124\n",
      "interval 125\n",
      "interval 126\n",
      "interval 127\n",
      "interval 128\n",
      "interval 129\n",
      "interval 130\n",
      "interval 131\n",
      "interval 132\n",
      "interval 133\n",
      "interval 134\n",
      "interval 135\n",
      "interval 136\n",
      "interval 137\n",
      "interval 138\n",
      "interval 139\n",
      "interval 140\n",
      "interval 141\n",
      "interval 142\n",
      "interval 143\n",
      "interval 144\n",
      "interval 145\n",
      "interval 146\n",
      "interval 147\n",
      "interval 148\n",
      "interval 149\n",
      "interval 150\n",
      "interval 151\n",
      "interval 152\n",
      "interval 153\n",
      "interval 154\n",
      "interval 155\n",
      "interval 156\n",
      "interval 157\n",
      "interval 158\n",
      "interval 159\n",
      "interval 160\n",
      "interval 161\n",
      "interval 162\n",
      "interval 163\n",
      "interval 164\n",
      "interval 165\n",
      "interval 166\n",
      "interval 167\n",
      "interval 168\n",
      "interval 169\n",
      "interval 170\n",
      "interval 171\n",
      "interval 172\n",
      "interval 173\n",
      "interval 174\n",
      "interval 175\n",
      "interval 176\n",
      "interval 177\n",
      "interval 178\n",
      "interval 179\n",
      "interval 180\n",
      "interval 181\n",
      "interval 182\n",
      "interval 183\n",
      "interval 184\n",
      "interval 185\n",
      "interval 186\n",
      "interval 187\n",
      "interval 188\n",
      "interval 189\n",
      "interval 190\n",
      "interval 191\n",
      "interval 192\n",
      "interval 193\n",
      "interval 194\n",
      "interval 195\n",
      "interval 196\n",
      "interval 197\n",
      "interval 198\n",
      "interval 199\n",
      "interval 200\n",
      "interval 201\n",
      "interval 202\n",
      "interval 203\n",
      "interval 204\n",
      "interval 205\n",
      "interval 206\n",
      "interval 207\n",
      "interval 208\n",
      "interval 209\n",
      "interval 210\n",
      "interval 211\n",
      "interval 212\n",
      "interval 213\n",
      "interval 214\n",
      "interval 215\n",
      "interval 216\n",
      "interval 217\n",
      "interval 218\n",
      "interval 219\n",
      "interval 220\n",
      "interval 221\n",
      "interval 222\n",
      "interval 223\n",
      "interval 224\n",
      "interval 225\n",
      "interval 226\n",
      "interval 227\n",
      "interval 228\n",
      "interval 229\n",
      "interval 230\n",
      "interval 231\n",
      "interval 232\n",
      "interval 233\n",
      "interval 234\n",
      "interval 235\n",
      "interval 236\n",
      "interval 237\n",
      "interval 238\n",
      "interval 239\n",
      "interval 240\n",
      "interval 241\n",
      "interval 242\n",
      "interval 243\n",
      "interval 244\n",
      "interval 245\n",
      "interval 246\n",
      "interval 247\n",
      "interval 248\n",
      "interval 249\n",
      "interval 250\n",
      "interval 251\n",
      "interval 252\n",
      "interval 253\n",
      "interval 254\n",
      "interval 255\n",
      "interval 256\n",
      "interval 257\n",
      "interval 258\n",
      "interval 259\n",
      "interval 260\n",
      "interval 261\n",
      "interval 262\n",
      "interval 263\n",
      "interval 264\n",
      "interval 265\n",
      "interval 266\n",
      "interval 267\n",
      "interval 268\n",
      "interval 269\n",
      "interval 270\n",
      "interval 271\n",
      "interval 272\n",
      "interval 273\n",
      "interval 274\n",
      "interval 275\n",
      "interval 276\n",
      "interval 277\n",
      "interval 278\n",
      "interval 279\n",
      "interval 280\n",
      "interval 281\n",
      "interval 282\n",
      "interval 283\n",
      "interval 284\n",
      "interval 285\n",
      "interval 286\n",
      "interval 287\n",
      "make numpy-array interval\n",
      "287\n",
      "make numpy-array points\n",
      "CPU times: user 6min 55s, sys: 736 ms, total: 6min 56s\n",
      "Wall time: 6min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for PID in participants:\n",
    "    for smartphone in smartphones:\n",
    "        print(\"processing:\", str(PID), smartphone)\n",
    "\n",
    "        # set screen resolution\n",
    "        if smartphone == \"N5X\":\n",
    "            pixels = {\"width\": 1080, \"height\": 1920}\n",
    "        elif smartphone == \"S3Mini\":\n",
    "            pixels = {\"width\": 480, \"height\": 800}\n",
    "        elif smartphone == \"S4\":\n",
    "            pixels = {\"width\": 1080, \"height\": 1920}\n",
    "        elif smartphone == \"N6\":\n",
    "            pixels = {\"width\": 1440, \"height\": 2560}\n",
    "\n",
    "        # Read Files\n",
    "        raw_data = dict()\n",
    "\n",
    "        for file in file_names:\n",
    "            file_path = str(Path.home()) + \"/data/raw/fapra_imu-\" +  str(PID) + \"-\" + file + \"-\" + smartphone + \"-\" + str(extension) + \".csv\"\n",
    "            if not os.path.isfile(file_path):\n",
    "                print(file_path + \"not found\")\n",
    "                continue\n",
    "            raw_data[file] = pd.read_csv(file_path, \";\")\n",
    "\n",
    "        # split by time in seperate lists\n",
    "        time_filtered_data = dict()\n",
    "        for name in file_names:\n",
    "            tmp = []\n",
    "            # remove [1:] if both lenght are equal (first press is removed)\n",
    "            for k, end in enumerate(raw_data[\"points\"].time[1:]):\n",
    "                start = int(raw_data[\"fitts\"].time[k])\n",
    "                # create mask for time interval\n",
    "                mask = (raw_data[name][\"time\"] > start) & (raw_data[name][\"time\"] <= end)\n",
    "                # only return items matching to mask\n",
    "                tmp.append(raw_data[name].loc[mask])\n",
    "            time_filtered_data[name] = tmp\n",
    "        # list to dataframe\n",
    "        time_filtered_data[\"points\"] = pd.concat(time_filtered_data[\"points\"])\n",
    "        time_filtered_data[\"fitts\"] = pd.concat(time_filtered_data[\"fitts\"])\n",
    "\n",
    "        # scale screen\n",
    "        time_filtered_data[\"points\"][\"x-press\"] = time_filtered_data[\"points\"][\"x-press\"].div(pixels[\"width\"])\n",
    "        time_filtered_data[\"points\"][\"x-circle\"] = time_filtered_data[\"points\"][\"x-circle\"].div(pixels[\"width\"])\n",
    "        time_filtered_data[\"points\"][\"y-press\"] = time_filtered_data[\"points\"][\"y-press\"].div(pixels[\"height\"])\n",
    "        time_filtered_data[\"points\"][\"y-circle\"] = time_filtered_data[\"points\"][\"y-circle\"].div(pixels[\"height\"])\n",
    "\n",
    "        # filter unique timestamps\n",
    "        for k, item in enumerate(time_filtered_data[\"points\"]):\n",
    "            for sensor in sensors:\n",
    "                time_filtered_data[sensor][k] = time_filtered_data[sensor][k].drop_duplicates(subset=\"time\", keep=\"last\")\n",
    "\n",
    "        # Create Array\n",
    "        result_interval = []\n",
    "        for k, point in time_filtered_data[\"points\"].iterrows():\n",
    "            print(\"create-interval\", k)\n",
    "            one_interval = []\n",
    "            interval = dict()\n",
    "            for sensor in sensors:\n",
    "                interval[sensor] = time_filtered_data[sensor][k - 1]\n",
    "\n",
    "            # keeps index of each sensor\n",
    "            position = dict()\n",
    "            # keeps value of last sensor event\n",
    "            last_values = dict()\n",
    "            for sensor in sensors:\n",
    "                position[sensor] = 0\n",
    "                last_values[sensor] = 0\n",
    "\n",
    "            # find maximum first timestamp in all sensors\n",
    "            current_time = -1\n",
    "            for sensor in sensors:\n",
    "                if interval[sensor][\"time\"].iloc[position[sensor]] > current_time:\n",
    "                    current_time = interval[sensor][\"time\"].iloc[position[sensor]]\n",
    "                last_values[sensor] = interval[sensor][:].iloc[position[sensor]]\n",
    "\n",
    "            # first result all values smaller then current_time\n",
    "            while True:\n",
    "                all_valid = True\n",
    "                for sensor in sensors:\n",
    "                    if interval[sensor][\"time\"].iloc[position[sensor] + 1] <= current_time:\n",
    "                        position[sensor] += 1\n",
    "                        last_values[sensor] = interval[sensor][:].iloc[position[sensor]]\n",
    "                        all_valid = False\n",
    "                if all_valid:\n",
    "                    break\n",
    "            one_interval.append(last_values)\n",
    "\n",
    "            # do until end of all sensor values\n",
    "            while True:\n",
    "                all_done = True\n",
    "                # find minimum next timestamp in all sensor\n",
    "                minimum = sys.maxsize\n",
    "                for sensor in sensors:\n",
    "                    if position[sensor] + 1 >= len(interval[sensor][\"time\"]):\n",
    "                        continue\n",
    "                    if interval[sensor][\"time\"].iloc[position[sensor] + 1] < minimum:\n",
    "                        minimum = interval[sensor][\"time\"].iloc[position[sensor] + 1]\n",
    "                current_time = minimum\n",
    "                # now assign all sensor that have minimum timestamp\n",
    "                for sensor in sensors:\n",
    "                    if position[sensor] + 1 >= len(interval[sensor][\"time\"]):\n",
    "                        continue\n",
    "                    if interval[sensor][\"time\"].iloc[position[sensor] + 1] <= current_time:\n",
    "                        position[sensor] += 1\n",
    "                        last_values[sensor] = interval[sensor][:].iloc[position[sensor]]\n",
    "                        all_done = False\n",
    "                one_interval.append(last_values)\n",
    "                if all_done:\n",
    "                    break\n",
    "            result_interval.append(one_interval)\n",
    "\n",
    "        # make numpy arrays (without dicts)\n",
    "        print(\"make numpy-array interval\")\n",
    "        final_intervals = []\n",
    "        for k, interval in enumerate(result_interval):\n",
    "            print(\"transpose-interval\", k)\n",
    "            current_interval = []\n",
    "            for i in interval:\n",
    "                event = []\n",
    "                for sensor in i.values():\n",
    "                    # except timestamp\n",
    "                    for value in sensor[1:]:\n",
    "                        event.append(value)\n",
    "                current_interval.append(np.asarray(event))\n",
    "            # make list to array, transpose and make 2d matrix\n",
    "            final_intervals.append(np.array(np.asarray(current_interval).transpose()))\n",
    "            \n",
    "        print(len(final_intervals))\n",
    "\n",
    "        print(\"make numpy-array points\")\n",
    "        final_points = time_filtered_data[\"points\"][['x-press','x-circle','y-press','y-circle']].values\n",
    "        final_result = [final_points, final_intervals]\n",
    "\n",
    "        # save dump pickles\n",
    "        data_path = str(Path.home()) + \"/data/pickles/fapra_imu-processed-\" +  str(PID) + \"-\" + smartphone + \".pkl\"\n",
    "        pkl.dump(final_result, open( data_path, \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = train_test_split(final_result, test_size=1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382 192\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), len(x_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
