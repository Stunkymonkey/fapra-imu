{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Importing matplotlib to plot images.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# for file-management\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Participant Infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = False\n",
    "participants = list(range(1, 21))\n",
    "smartphones = [\"S3Mini\", \"S4\", \"N5X\", \"N6\"]\n",
    "# TODO remove\n",
    "participants = list(range(1, 18))\n",
    "smartphones = [\"N5X\"]\n",
    "event_time_diff = 3\n",
    "window_size = 20\n",
    "normalize_screen = False\n",
    "\n",
    "sensors = [\n",
    "    \"acc\",\n",
    "    \"gyro\",\n",
    "    \"ori\",\n",
    "    \"grav\",\n",
    "    \"mag\",\n",
    "    \"rot\"\n",
    "]\n",
    "\n",
    "tasks = [\n",
    "    \"points\",\n",
    "    \"fitts\"\n",
    "]\n",
    "\n",
    "file_names = sensors + tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing - participant: 1 smartphone: N5X\n",
      "processing - participant: 2 smartphone: N5X\n",
      "processing - participant: 3 smartphone: N5X\n",
      "processing - participant: 4 smartphone: N5X\n",
      "processing - participant: 5 smartphone: N5X\n",
      "processing - participant: 6 smartphone: N5X\n",
      "processing - participant: 7 smartphone: N5X\n",
      "processing - participant: 8 smartphone: N5X\n",
      "processing - participant: 9 smartphone: N5X\n",
      "processing - participant: 10 smartphone: N5X\n",
      "processing - participant: 11 smartphone: N5X\n",
      "processing - participant: 12 smartphone: N5X\n",
      "processing - participant: 13 smartphone: N5X\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "segments = list()\n",
    "labels = list()\n",
    "groups = list()\n",
    "\n",
    "for smartphone in smartphones:\n",
    "    for PID in participants:\n",
    "        print(\"processing - participant:\", str(PID), \"smartphone:\", smartphone)\n",
    "\n",
    "        # set screen resolution\n",
    "        if smartphone == \"N5X\":\n",
    "            pixels = {\"width\": 1080, \"height\": 1920}\n",
    "        elif smartphone == \"S3Mini\":\n",
    "            pixels = {\"width\": 480, \"height\": 800}\n",
    "        elif smartphone == \"S4\":\n",
    "            pixels = {\"width\": 1080, \"height\": 1920}\n",
    "        elif smartphone == \"N6\":\n",
    "            pixels = {\"width\": 1440, \"height\": 2560}\n",
    "\n",
    "        # Read Files\n",
    "        raw_data = dict()\n",
    "\n",
    "        if output: print(\"read files\")\n",
    "        for file in file_names:\n",
    "            file_path = str(Path.home()) + \"/data/raw/fapra_imu-\" +  str(PID) + \"-\" + file + \"-\" + smartphone + \"-0.csv\"\n",
    "            if not os.path.isfile(file_path):\n",
    "                print(file_path + \"not found\")\n",
    "                continue\n",
    "            raw_data[file] = pd.read_csv(file_path, \";\")\n",
    "\n",
    "        # split by time in seperate lists\n",
    "        if output: print(\"sort to specific interval\")\n",
    "        time_filtered_data = dict()\n",
    "        for name in file_names:\n",
    "            tmp = []\n",
    "            for k, end in enumerate(raw_data[\"points\"].time):\n",
    "                start = int(raw_data[\"fitts\"].time[k])\n",
    "                # create mask for time interval\n",
    "                mask = (raw_data[name][\"time\"] > start) & (raw_data[name][\"time\"] <= end)\n",
    "                # only return items matching to mask\n",
    "                tmp.append(raw_data[name].loc[mask])\n",
    "            time_filtered_data[name] = tmp\n",
    "        # list to dataframe\n",
    "        time_filtered_data[\"points\"] = pd.concat(time_filtered_data[\"points\"])\n",
    "\n",
    "        # scale screen\n",
    "        if normalize_screen:\n",
    "            time_filtered_data[\"points\"][\"x-press\"] = time_filtered_data[\"points\"][\"x-press\"].div(pixels[\"width\"])\n",
    "            time_filtered_data[\"points\"][\"x-circle\"] = time_filtered_data[\"points\"][\"x-circle\"].div(pixels[\"width\"])\n",
    "            time_filtered_data[\"points\"][\"y-press\"] = time_filtered_data[\"points\"][\"y-press\"].div(pixels[\"height\"])\n",
    "            time_filtered_data[\"points\"][\"y-circle\"] = time_filtered_data[\"points\"][\"y-circle\"].div(pixels[\"height\"])\n",
    "\n",
    "        # filter unique timestamps\n",
    "        for k, item in enumerate(time_filtered_data[\"points\"]):\n",
    "            for sensor in sensors:\n",
    "                time_filtered_data[sensor][k] = time_filtered_data[sensor][k].drop_duplicates(subset=\"time\", keep=\"last\")\n",
    "        \n",
    "        # Create Array\n",
    "        result_interval = []\n",
    "        if output: print(\"create-interval\", end=' ')\n",
    "        for k, point in time_filtered_data[\"points\"].iterrows():\n",
    "            if output: print(k, end=' ', flush=True)\n",
    "            one_interval = []\n",
    "            interval = dict()\n",
    "            for sensor in sensors:\n",
    "                interval[sensor] = time_filtered_data[sensor][k]\n",
    "\n",
    "            # keeps index of each sensor\n",
    "            position = dict()\n",
    "            # keeps value of last sensor event\n",
    "            last_values = dict()\n",
    "            for sensor in sensors:\n",
    "                position[sensor] = 0\n",
    "                last_values[sensor] = 0\n",
    "\n",
    "            # find maximum first timestamp in all sensors\n",
    "            current_time = -1\n",
    "            for sensor in sensors:\n",
    "                if interval[sensor][\"time\"].iloc[position[sensor]] > current_time:\n",
    "                    current_time = interval[sensor][\"time\"].iloc[position[sensor]]\n",
    "                last_values[sensor] = interval[sensor][:].iloc[position[sensor]]\n",
    "            \n",
    "            # print(\"start\", raw_data[\"fitts\"].time.iloc[k])\n",
    "            # print(\"first_data\", current_time)\n",
    "            # print(\"end\", time_filtered_data[\"points\"].iloc[k][\"time\"])\n",
    "\n",
    "            # iterate as long as time has not reached max\n",
    "            while current_time <= time_filtered_data[\"points\"].iloc[k][\"time\"]:\n",
    "                # iterate over alle sensors to find values before current_time (maybe one sensor is having multiple updates)\n",
    "                while True:\n",
    "                    all_valid = True\n",
    "                    for sensor in sensors:\n",
    "                        if position[sensor] + 1 >= len(interval[sensor][\"time\"]):\n",
    "                            continue\n",
    "                        if interval[sensor][\"time\"].iloc[position[sensor] + 1] <= current_time:\n",
    "                            position[sensor] += 1\n",
    "                            last_values[sensor] = interval[sensor][:].iloc[position[sensor]]\n",
    "                            all_valid = False\n",
    "                    if all_valid:\n",
    "                        break\n",
    "                one_interval.append(last_values.copy())\n",
    "                current_time = current_time + event_time_diff\n",
    "            result_interval.append(one_interval)\n",
    "        \n",
    "        # make numpy arrays (without dicts)\n",
    "        if output: print()\n",
    "        if output: print(\"make numpy-array interval\", end=' ')\n",
    "        final_intervals = []\n",
    "        for k, interval in enumerate(result_interval):\n",
    "            if output: print(k, end=' ', flush=True)\n",
    "            current_interval = []\n",
    "            for i in interval:\n",
    "                event = []\n",
    "                for sensor in i.values():\n",
    "                    # except timestamp\n",
    "                    for value in sensor[1:]:\n",
    "                        event.append(value)\n",
    "                current_interval.append(np.asarray(event))\n",
    "            # make list to array, transpose and make 2d matrix\n",
    "            final_intervals.append(np.array(np.asarray(current_interval).transpose()))\n",
    "        \n",
    "        if output: print()\n",
    "        if output: print(\"make numpy-array points\")\n",
    "        final_points = time_filtered_data[\"points\"][['x-circle', 'y-circle', 'x-press', 'y-press']].values\n",
    "        \n",
    "        points = final_points\n",
    "        intervals = final_intervals\n",
    "        # split the points to according group\n",
    "        cross = points[:,:2]\n",
    "        pressed = points[:,2:]\n",
    "        \n",
    "        # iterate over intervals\n",
    "        for i, c in zip(intervals, pressed):\n",
    "            samples_per_interval = len(i[0]) - (window_size - 1)\n",
    "            # create array of same label\n",
    "            tmp_labels = [c] * samples_per_interval\n",
    "            tmp_labels = np.array(tmp_labels)\n",
    "            labels.append(tmp_labels)\n",
    "            tmp_groups = [PID] * samples_per_interval\n",
    "            groups = groups + tmp_groups\n",
    "            for k in range(len(i.T[(window_size - 1):])):\n",
    "                chunk = np.array(i.T[k:(k + window_size)])\n",
    "                segments.append(chunk)\n",
    "\n",
    "    # make numpy arrays of it\n",
    "    labels = np.concatenate(np.array(labels))\n",
    "    segments = np.array(segments)\n",
    "    groups = np.array(groups, dtype=np.int8)\n",
    "    \n",
    "    hf = h5py.File(str(Path.home()) + \"/data/hdf/\" + smartphone + \"-\" + str(window_size) + \".hdf\", \"w\")\n",
    "    file_group = hf.create_group('fapra_imu')\n",
    "    ds_l = file_group.create_dataset(\"labels\", data=labels)\n",
    "    ds_s = file_group.create_dataset(\"segments\", data=segments)\n",
    "    ds_g = file_group.create_dataset(\"groups\", data=groups)\n",
    "    hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
