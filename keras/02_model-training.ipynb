{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Importing matplotlib to plot images.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing SK-learn to calculate precision and recall\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneGroupOut\n",
    "\n",
    "# Used for graph export\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras import backend as K\n",
    "\n",
    "import pickle as pkl\n",
    "import h5py\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "# config = tf.ConfigProto(device_count = {\"GPU\": 0})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "# Limit the maximum memory used\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "\n",
    "# set session config\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "smartphones = [\"N5X\"]\n",
    "# TODO remove\n",
    "participants = list(range(1, 4))\n",
    "window_size = 20\n",
    "constant_pixels = 0.06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H5DF files contains 3 members: labels, segments, groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = str(Path.home())+\"/data/hdf/\"+smartphones[0]+\"-\"+str(window_size)+\".hdf\"\n",
    "f = h5py.File(filename, 'r')\n",
    "# List all groups\n",
    "#print(\"Keys: %s\" % f.keys())\n",
    "list(f.keys())\n",
    "groups = f['fapra_imu']['groups'][()]\n",
    "labels = f['fapra_imu']['labels'][()]\n",
    "segments = f['fapra_imu']['segments'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1446987, 2)\n",
      "(1446987, 20, 18)\n",
      "(1446987,)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)\n",
    "print(segments.shape)\n",
    "print(groups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining parameters for the input and network layers\n",
    "## we are treating each segmeent or chunk as a 2D image (90 X 18)\n",
    "numOfRows = segments.shape[1]\n",
    "numOfColumns = segments.shape[2]\n",
    "\n",
    "## reshaping the data for network input\n",
    "reshapedSegments = segments.reshape(segments.shape[0], numOfRows, numOfColumns,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training- & Test-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(segments, labels, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ConvLSTM net hyperparameters\n",
    "numChannels = 1\n",
    "numFilters = 128 # number of filters in Conv2D layer\n",
    "# kernal size of the Conv2D layer\n",
    "kernalSize1 = 1\n",
    "# max pooling window size\n",
    "poolingWindowSz = 2\n",
    "# number of filters in fully connected layers\n",
    "numNueronsFCL1 = 256\n",
    "numNueronsFCL2 = 128\n",
    "# number of epochs\n",
    "Epochs = 10\n",
    "# batchsize\n",
    "batchSize = 200\n",
    "# number of total clases\n",
    "numClasses = labels.shape[1]\n",
    "# dropout ratio for dropout layer\n",
    "dropOutRatio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d_3 (ConvLSTM2D)  (None, None, 20, 18, 128) 66560     \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, None, 10, 9, 128)  0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, None, 10, 9, 128)  0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, None, 11520)       0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, None, 256)         2949376   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, None, 128)         32896     \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, None, 2)           258       \n",
      "=================================================================\n",
      "Total params: 3,049,090\n",
      "Trainable params: 3,049,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1363450 samples, validate on 83537 samples\n",
      "Epoch 1/9999\n",
      "1363450/1363450 [==============================] - 336s 247us/step - loss: 381.5864 - eucInMM: 32.3787 - rmse: 381.5864 - euc: 539.6447 - val_loss: 364.3977 - val_eucInMM: 30.9202 - val_rmse: 364.3977 - val_euc: 515.3362\n",
      "Epoch 2/9999\n",
      "1363450/1363450 [==============================] - 336s 246us/step - loss: 378.9139 - eucInMM: 32.1519 - rmse: 378.9139 - euc: 535.8652 - val_loss: 362.5332 - val_eucInMM: 30.7620 - val_rmse: 362.5332 - val_euc: 512.6994\n",
      "Epoch 3/9999\n",
      "1363450/1363450 [==============================] - 336s 246us/step - loss: 378.0033 - eucInMM: 32.0746 - rmse: 378.0033 - euc: 534.5775 - val_loss: 361.4776 - val_eucInMM: 30.6724 - val_rmse: 361.4776 - val_euc: 511.2065\n",
      "Epoch 4/9999\n",
      "1363450/1363450 [==============================] - 336s 246us/step - loss: 377.3611 - eucInMM: 32.0201 - rmse: 377.3611 - euc: 533.6691 - val_loss: 360.7128 - val_eucInMM: 30.6075 - val_rmse: 360.7128 - val_euc: 510.1250\n",
      "Epoch 5/9999\n",
      "1363450/1363450 [==============================] - 336s 246us/step - loss: 376.8410 - eucInMM: 31.9760 - rmse: 376.8410 - euc: 532.9337 - val_loss: 359.9777 - val_eucInMM: 30.5451 - val_rmse: 359.9777 - val_euc: 509.0853\n",
      "Epoch 6/9999\n",
      "1337200/1363450 [============================>.] - ETA: 6s - loss: 376.4138 - eucInMM: 31.9398 - rmse: 376.4138 - euc: 532.3296"
     ]
    }
   ],
   "source": [
    "tf.get_default_graph()\n",
    "for index, (train_index, test_index) in enumerate(logo.split(reshapedSegments, labels, groups)):\n",
    "\n",
    "    # print('TRAIN:', train_index, 'TEST:', test_index)\n",
    "    trainX, testX = reshapedSegments[train_index], reshapedSegments[test_index]\n",
    "    trainY, testY = labels[train_index], labels[test_index]\n",
    "    \n",
    "    model = None\n",
    "    model = Sequential()\n",
    "    # adding the first convLSTM layer with 32 filters and 5 by 5 kernal size, using the rectifier as the activation function\n",
    "    model.add(ConvLSTM2D(numFilters, (kernalSize1,kernalSize1),input_shape=(None, numOfRows, numOfColumns, 1),activation='relu', padding='same',return_sequences=True))\n",
    "\n",
    "    ## adding a maxpooling layer\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(poolingWindowSz,poolingWindowSz),padding='valid')))\n",
    "\n",
    "    ## adding a dropout layer for the regularization and avoiding over fitting\n",
    "    model.add(Dropout(dropOutRatio))\n",
    "\n",
    "    ## flattening the output in order to apple dense layer\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "    ## adding first fully connected layer with 256 outputs\n",
    "    model.add(Dense(numNueronsFCL1, activation='relu'))\n",
    "\n",
    "    ## adding second fully connected layer 128 outputs\n",
    "    model.add(Dense(numNueronsFCL2, activation='relu'))\n",
    "\n",
    "    ## flattening the output in order to apply the fully connected layer\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "    ## adding softmax layer for the classification\n",
    "    model.add(Dense(numClasses)) #, activation='softmax'\n",
    "\n",
    "    ## Compiling the model to generate a model\n",
    "    def eucInMM(y_true, y_pred):\n",
    "        return (K.sqrt(K.sum(K.square(y_true - y_pred), axis=-1, keepdims=True))) * constant_pixels\n",
    "    def rmse(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
    "    \n",
    "    def euc(y_true, y_pred):\n",
    "        return K.sqrt(K.sum(K.square(y_true - y_pred), axis=-1, keepdims=True))\n",
    "    \n",
    "    #optimizer = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    #optimizer = optimizers.Adam(lr = 0.001, decay=1e-6)\n",
    "    optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.1)\n",
    "    model.compile(loss=rmse, optimizer=optimizer, metrics=[eucInMM ,rmse, euc])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    history = model.fit(np.expand_dims(trainX,1),np.expand_dims(trainY,1), \n",
    "                        validation_data=(np.expand_dims(testX,1),np.expand_dims(testY,1)),\n",
    "                        epochs=9999,batch_size=batchSize,verbose=1)\n",
    "\n",
    "    score = model.evaluate(np.expand_dims(testX,1),np.expand_dims(testY,1),verbose=2)\n",
    "    print('%s: %.2f' % (model.metrics_names[1], score[1]))\n",
    "    print('Baseline ConvLSTM Error: %.2f' %(1-score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10936 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
