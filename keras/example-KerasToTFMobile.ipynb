{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.23) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = \"IndexVsThumb\"\n",
    "\n",
    "input_path = \"./\"\n",
    "input_file = modelname + \".h5\"\n",
    "\n",
    "output_path = \"./\"\n",
    "output_file = modelname + \".pb\"\n",
    "\n",
    "output_node_prefix = \"output_node\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output nodes names are:  ['output_node0']\n"
     ]
    }
   ],
   "source": [
    "K.set_learning_phase(0)\n",
    "net_model = load_model(input_path + input_file)\n",
    "\n",
    "num_output = 1\n",
    "pred = [None]*num_output\n",
    "pred_node_names = [None]*num_output\n",
    "for i in range(num_output):\n",
    "    pred_node_names[i] = output_node_prefix+str(i)\n",
    "    pred[i] = tf.identity(net_model.outputs[i], name=pred_node_names[i])\n",
    "print('output nodes names are: ', pred_node_names)\n",
    "output_node_prefix = pred_node_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 32 variables.\n",
      "Converted 32 variables to const ops.\n",
      "Saved the freezed graph at:  ./IndexVsThumb.pb\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), pred_node_names)\n",
    "\n",
    "graph_io.write_graph(constant_graph, output_path, output_file, as_text=False)\n",
    "\n",
    "print('Saved the freezed graph at: ', (output_path + output_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show input and output node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_1_input\n",
      "conv2d_1/kernel\n",
      "conv2d_1/kernel/read\n",
      "conv2d_1/bias\n",
      "conv2d_1/bias/read\n",
      "conv2d_1/convolution\n",
      "conv2d_1/BiasAdd\n",
      "conv2d_1/Relu\n",
      "batch_normalization_1/gamma\n",
      "batch_normalization_1/gamma/read\n",
      "batch_normalization_1/beta\n",
      "batch_normalization_1/beta/read\n",
      "batch_normalization_1/moving_mean\n",
      "batch_normalization_1/moving_mean/read\n",
      "batch_normalization_1/moving_variance\n",
      "batch_normalization_1/moving_variance/read\n",
      "batch_normalization_1/batchnorm/add/y\n",
      "batch_normalization_1/batchnorm/add\n",
      "batch_normalization_1/batchnorm/Rsqrt\n",
      "batch_normalization_1/batchnorm/mul\n",
      "batch_normalization_1/batchnorm/mul_1\n",
      "batch_normalization_1/batchnorm/mul_2\n",
      "batch_normalization_1/batchnorm/sub\n",
      "batch_normalization_1/batchnorm/add_1\n",
      "conv2d_2/kernel\n",
      "conv2d_2/kernel/read\n",
      "conv2d_2/bias\n",
      "conv2d_2/bias/read\n",
      "conv2d_2/convolution\n",
      "conv2d_2/BiasAdd\n",
      "conv2d_2/Relu\n",
      "batch_normalization_2/gamma\n",
      "batch_normalization_2/gamma/read\n",
      "batch_normalization_2/beta\n",
      "batch_normalization_2/beta/read\n",
      "batch_normalization_2/moving_mean\n",
      "batch_normalization_2/moving_mean/read\n",
      "batch_normalization_2/moving_variance\n",
      "batch_normalization_2/moving_variance/read\n",
      "batch_normalization_2/batchnorm/add/y\n",
      "batch_normalization_2/batchnorm/add\n",
      "batch_normalization_2/batchnorm/Rsqrt\n",
      "batch_normalization_2/batchnorm/mul\n",
      "batch_normalization_2/batchnorm/mul_1\n",
      "batch_normalization_2/batchnorm/mul_2\n",
      "batch_normalization_2/batchnorm/sub\n",
      "batch_normalization_2/batchnorm/add_1\n",
      "max_pooling2d_1/MaxPool\n",
      "dropout_1/Identity\n",
      "conv2d_3/kernel\n",
      "conv2d_3/kernel/read\n",
      "conv2d_3/bias\n",
      "conv2d_3/bias/read\n",
      "conv2d_3/convolution\n",
      "conv2d_3/BiasAdd\n",
      "conv2d_3/Relu\n",
      "batch_normalization_3/gamma\n",
      "batch_normalization_3/gamma/read\n",
      "batch_normalization_3/beta\n",
      "batch_normalization_3/beta/read\n",
      "batch_normalization_3/moving_mean\n",
      "batch_normalization_3/moving_mean/read\n",
      "batch_normalization_3/moving_variance\n",
      "batch_normalization_3/moving_variance/read\n",
      "batch_normalization_3/batchnorm/add/y\n",
      "batch_normalization_3/batchnorm/add\n",
      "batch_normalization_3/batchnorm/Rsqrt\n",
      "batch_normalization_3/batchnorm/mul\n",
      "batch_normalization_3/batchnorm/mul_1\n",
      "batch_normalization_3/batchnorm/mul_2\n",
      "batch_normalization_3/batchnorm/sub\n",
      "batch_normalization_3/batchnorm/add_1\n",
      "conv2d_4/kernel\n",
      "conv2d_4/kernel/read\n",
      "conv2d_4/bias\n",
      "conv2d_4/bias/read\n",
      "conv2d_4/convolution\n",
      "conv2d_4/BiasAdd\n",
      "conv2d_4/Relu\n",
      "batch_normalization_4/gamma\n",
      "batch_normalization_4/gamma/read\n",
      "batch_normalization_4/beta\n",
      "batch_normalization_4/beta/read\n",
      "batch_normalization_4/moving_mean\n",
      "batch_normalization_4/moving_mean/read\n",
      "batch_normalization_4/moving_variance\n",
      "batch_normalization_4/moving_variance/read\n",
      "batch_normalization_4/batchnorm/add/y\n",
      "batch_normalization_4/batchnorm/add\n",
      "batch_normalization_4/batchnorm/Rsqrt\n",
      "batch_normalization_4/batchnorm/mul\n",
      "batch_normalization_4/batchnorm/mul_1\n",
      "batch_normalization_4/batchnorm/mul_2\n",
      "batch_normalization_4/batchnorm/sub\n",
      "batch_normalization_4/batchnorm/add_1\n",
      "max_pooling2d_2/MaxPool\n",
      "dropout_2/Identity\n",
      "flatten_1/Shape\n",
      "flatten_1/strided_slice/stack\n",
      "flatten_1/strided_slice/stack_1\n",
      "flatten_1/strided_slice/stack_2\n",
      "flatten_1/strided_slice\n",
      "flatten_1/Const\n",
      "flatten_1/Prod\n",
      "flatten_1/stack/0\n",
      "flatten_1/stack\n",
      "flatten_1/Reshape\n",
      "dense_1/kernel\n",
      "dense_1/kernel/read\n",
      "dense_1/bias\n",
      "dense_1/bias/read\n",
      "dense_1/MatMul\n",
      "dense_1/BiasAdd\n",
      "dense_1/Relu\n",
      "batch_normalization_5/gamma\n",
      "batch_normalization_5/gamma/read\n",
      "batch_normalization_5/beta\n",
      "batch_normalization_5/beta/read\n",
      "batch_normalization_5/moving_mean\n",
      "batch_normalization_5/moving_mean/read\n",
      "batch_normalization_5/moving_variance\n",
      "batch_normalization_5/moving_variance/read\n",
      "batch_normalization_5/batchnorm_1/add/y\n",
      "batch_normalization_5/batchnorm_1/add\n",
      "batch_normalization_5/batchnorm_1/Rsqrt\n",
      "batch_normalization_5/batchnorm_1/mul\n",
      "batch_normalization_5/batchnorm_1/mul_1\n",
      "batch_normalization_5/batchnorm_1/mul_2\n",
      "batch_normalization_5/batchnorm_1/sub\n",
      "batch_normalization_5/batchnorm_1/add_1\n",
      "dropout_3/Identity\n",
      "dense_2/kernel\n",
      "dense_2/kernel/read\n",
      "dense_2/bias\n",
      "dense_2/bias/read\n",
      "dense_2/MatMul\n",
      "dense_2/BiasAdd\n",
      "dense_2/Softmax\n",
      "output_node0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g = tf.GraphDef()\n",
    "g.ParseFromString(open(output_path + output_file, \"rb\").read())\n",
    "s = \"\"\n",
    "for n in g.node:\n",
    "    s =s + str(n.name) + \"\\n\"\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_node = \"conv2d_1_input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testArr = np.array([0.018656716, 0.03731343, 0.041044775, 0.05970149, 0.041044775, 0.041044775, 0.03358209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018656716, 0.06716418, 0.1716418, 0.23134328, 0.18656716, 0.11940298, 0.048507463, 0.03358209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041044775, 0.38432837, 0.78731346, 0.8731343, 0.8208955, 0.619403, 0.19402985, 0.0858209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07089552, 0.6119403, 0.9477612, 0.9701493, 0.95522386, 0.79850745, 0.25, 0.14925373, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048507463, 0.2761194, 0.6455224, 0.7910448, 0.73507464, 0.3955224, 0.14179105, 0.07835821, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026119404, 0.07089552, 0.14925373, 0.20522387, 0.18283582, 0.11567164, 0.05970149, 0.048507463, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "finger = np.array([0.0, 0.03358209, 0.10074627, 0.06716418, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018656716, 0.31716418, 0.72761196, 0.38059703, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041044775, 0.70522386, 1.0186567, 0.77238804, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0074626864, 0.4552239, 0.8544776, 0.53731346, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05970149, 0.1716418, 0.10074627, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "testArr = testArr.reshape(1, 27, 15, 1)\n",
    "finger = finger.reshape(1, 27, 15, 1)\n",
    "\n",
    "y_pred = sess.graph.get_tensor_by_name(output_node_prefix + \":0\")\n",
    "x= sess.graph.get_tensor_by_name(input_node + \":0\")\n",
    "\n",
    "y_test_images = np.zeros((1, 2))\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    feed_dict_testing = {x: finger}\n",
    "    result = sess.run(y_pred, feed_dict=feed_dict_testing)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://github.com/amir-abdi/keras_to_tensorflow/blob/master/keras_to_tensorflow.ipynb\n",
    "# More information (especially fixes for Keras stuff): https://github.com/madhavajay/what-dog/blob/master/model_converter/keras_to_tensorflow.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
