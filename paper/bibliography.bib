@inproceedings{Le:2018:PalmTouch,
title = {PalmTouch: Using the Palm as an Additional Input Modality on Commodity Smartphones},
author = {Huy Viet Le and Thomas Kosch and Patrick Bader and Sven Mayer and Niels Henze},
url = {http://sven-mayer.com/wp-content/uploads/2018/01/le2018palmtouch.pdf},
doi = {10.1145/3173574.3173934},
year = {2018},
date = {2018-04-21},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {360:1--360:13},
publisher = {ACM},
address = {New York, NY, USA},
series = {CHI'18},
abstract = {Touchscreens are the most successful input method for smartphones. Despite their flexibility, touch input is limited to the location of taps and gestures. We present PalmTouch, an additional input modality that differentiates between touches of fingers and the palm. Touching the display with the palm can be a natural gesture since moving the thumb towards the device's top edge implicitly places the palm on the touchscreen. We present different use cases for PalmTouch, including the use as a shortcut and for improving reachability. To evaluate these use cases, we have developed a model that differentiates between finger and palm touch with an accuracy of 99.53% in realistic scenarios. Results of the evaluation show that participants perceive the input modality as intuitive and natural to perform. Moreover, they appreciate PalmTouch as an easy and fast solution to address the reachability issue during one-handed smartphone interaction compared to thumb stretching or grip changes.},
keywords = {},
pubstate = {published},
tppubtype = {inproceedings}
}
@article{Poston,
abstract = {SubTAG of the Department of Defense Human Factors Engineering Technical Advisory Group (DoD HFE TAG). This booklet is a digest of material appearing in MIL-STD-1472, and is complemented with material from MIL-HDBK-759 and the Federal Aviation Administration (FAA) Human Factors Design Guide. The user is therefore referred to those documents and its references for required supplementary information. This digest provides basic, quantitative human engineering design data in pictorial, tabular, and graphical formats for use during system, equipment, or facility design and assessment. Its purpose is to furnish a convenient “portable” reference of human engineering design criteria and guidelines. The principles, explanations, limitations, and application techniques associated with the data have been intentionally omitted. This abbreviated presentation presupposes that the user is familiar with the bases and limitations of the given data or will consult applicable references to ensure appropriate application of the data.},
author = {Poston, Alan},
journal = {Department of Defense Human Factors Engineering Technical Advisory Group Washington},
pages = {82},
title = {{Human engineering design data digest}},
url = {https://www.acq.osd.mil/rd/hptb/hfetag/products/documents/HE_Design_Data_Digest.pdf},
year = {2000}
}
@inproceedings{Corsten2017,
abstract = {When people hold their smartphone in landscape orientation, they use their thumbs for input on the frontal touchscreen, while their remaining fingers rest on the back of the device (BoD) to stabilize the grip. We present BackXPress, a new interaction technique that lets users create BoD pressure input with these remaining fingers to augment their interaction with the touchscreen on the front: Users can apply various pressure levels with each of these fingers to enter different temporary “quasi-modes” that are only active as long as that pressure is applied. Both thumbs can then interact with the frontal screen in that mode. We illustrate the practicality of BackXPress with several sample applications, and report our results from three user studies: Study 1 investigated which fingers can be used to exert BoD pressure and found index, middle, and ring finger from both hands to be practical. Study 2 revealed how pressure touches from these six fingers are distributed across the BoD. Study 3 examined user performance for applying BoD pressure (a) during single touches at the front and (b) for 20 seconds while touching multiple consecutive frontal targets. Participants achieved up to 92{\%} pressure accuracy for three separate pressure levels above normal resting pressure, with the middle fingers providing the highest accuracy. BoD pressure did not affect frontal touch accuracy. We conclude with design guidelines for BoD pressure input.},
address = {New York, New York, USA},
author = {Corsten, Christian and Daehlmann, Bjoern and Voelker, Simon and Borchers, Jan},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems - CHI '17},
doi = {10.1145/3025453.3025565},
file = {:C$\backslash$:/Users/bsteu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Corsten et al. - Unknown - BackXPress Using Back-of-Device Finger Pressure to Augment Touchscreen Input on Smartphones.pdf:pdf},
isbn = {9781450346559},
keywords = {Back-of-Device,bimanual input,pressure,smartphone},
pages = {4654--4666},
publisher = {ACM Press},
title = {{BackXPress}},
url = {http://delivery.acm.org/10.1145/3030000/3025565/p4654-corsten.pdf?ip=141.58.42.123&id=3025565&acc=ACTIVE SERVICE&key=2BA2C432AB83DA15.B24C68F3238D7605.4D4702B0C3E38B35.4D4702B0C3E38B35&__acm__=1527693800_e8138247293960788ef33aac098d7e1a http://dl.acm.org/},
year = {2017}
}
@inproceedings{DeLuca2013,
abstract = {This paper presents BoD Shapes, a novel authentication method for smartphones that uses the back of the device for input. We argue that this increases the resistance to shoulder surfing while remaining reasonably fast and easy-to-use. We performed a user study (n=24) comparing BoD Shapes to PIN authentication, Android grid unlock, and a front version of our system. Testing a front version allowed us to directly compare performance and security measures between front and back authentication. Our results show that BoD Shapes is significantly more secure than the three other approaches. While performance declined, our results show that BoD Shapes can be very fast (up to 1.5 seconds in the user study) and that learning effects have an influence on its performance. This indicates that speed improvements can be expected in long-term use.},
author = {{De Luca}, Alexander and von Zezschwitz, Emanuel and Nguyen, Ngo Dieu Huong and Maurer, Max-Emanuel and Rubegni, Elisa and Scipioni, Marcello Paolo and Langheinrich, Marc},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2481330},
file = {:C$\backslash$:/Users/bsteu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/De Luca et al. - Unknown - Back-of-Device Authentication on Smartphones.pdf:pdf},
isbn = {9781450318990},
keywords = {SIGCHI,archival format,proceedings},
pages = {2389},
title = {{Back-of-device authentication on smartphones}},
url = {https://www.medien.ifi.lmu.de/pubdb/publications/pub/deluca2013chi2/deluca2013chi2.pdf http://dl.acm.org/citation.cfm?doid=2470654.2481330},
year = {2013}
}
@article{Shen,
abstract = {We present a new mobile interaction model, called double-side multi-touch, based on a mobile device that receives simultaneous multi-touch input from both the front and the back of the device. This new double-sided multi-touch mobile interaction model enables intuitive finger gestures for manipulating 3D objects and user interfaces on a 2D screen.},
author = {Shen, Ee and Tsai, Sd and Chu, Hao-Hua and Hsu, Yj and Chen, Ce},
doi = {10.1145/1520340.1520663},
file = {:C$\backslash$:/Users/bsteu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shen et al. - Unknown - Double-side Multi-touch Input for Mobile Devices.pdf:pdf},
isbn = {9781605582474},
journal = {Proceedings of the 27th international conference},
keywords = {double-side multi-touch,finger touch gesture,mobile},
pages = {4339--4344},
title = {{Double-side multi-touch input for mobile devices}},
url = {http://mll.csie.ntu.edu.tw/papers/DoubleSideMultiTouchInputForMobileDevices_Chi09.pdf},
year = {2009}
}
@inproceedings{Wolf2012,
abstract = {... Shen [16] investigated double-sided multi touch providing a see- through vision of the fingers position on the ... 1) that tracks multitouch events using the TUIO protocol. ... For these gestures we analyzed the pointing accuracy through identifying the finger that was selected through ... $\backslash$n},
address = {New York, New York, USA},
author = {Wolf, Katrin and M{\"{u}}ller-Tomfelde, Christian and Cheng, Kelvin and Wechsung, Ina},
booktitle = {Proceedings of the Sixth International Conference on Tangible, Embedded and Embodied Interaction - TEI '12},
doi = {10.1145/2148131.2148155},
isbn = {9781450311748},
keywords = {Author Keywords Pinch,Design,Experimentation,Human Factors,Interaction styles General Terms Performance,body schema,gesture,grasp,mobile devices},
pages = {103},
publisher = {ACM Press},
title = {{PinchPad}},
url = {http://katrinwolf.info/wp-content/uploads/2013/05/TEI2012_pinchPad-InProc1.pdf http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=pubmed&cmd=Retrieve&dopt=AbstractPlus&list_uids=18295156742687528349related:nZX7JSB05f0J%5Cnfile:///Users/grahamwilson/Document},
year = {2012}
}
@article{Yoo,
abstract = {This paper evaluates how the "index finger zone " on the back of a smartphone could compensate for the limitations of the " thumb space. " We conducted two experiments to investigate how to reach to a distant point comfortably with one hand. First, we gave the participants four typical tasks while using mobile phones (tapping, texting, calling, and scrolling). In these situations, we measured the position of the index finger and the thumb with the natural hand posture. Consequently, the index finger was primarily positioned in the upper left side. Second, the main experiment was to determine how a touchable area could be extended using the index finger zone on the back side. 1) Randomly selected tiles were touched 84 times with a thumb and 42 times with an index finger. 2) Each tile's preference was evaluated with a 5-point Likert scale. As a result, we found that the " comfort zone " could be expanded by 15{\%} by using index finger zone.},
author = {Yoo, Hyunjin and Yoon, Jungwon and Ji, Hyunsoo},
doi = {10.1145/2786567.2793704},
file = {:C$\backslash$:/Users/bsteu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Yoo, Yoon, Ji - Unknown - Index Finger Zone Study on Touchable Area Expandability Using Thumb and Index Finger.pdf:pdf},
isbn = {9781450336536},
journal = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
keywords = {Author Keywords Back Touch Interface,Reachability,Touchable Area},
pages = {803--810},
title = {{Index Finger Zone : Study on Touchable Area Expandability Using Thumb and Index Finger}},
url = {http://dx.doi.org/10.1145/2786567.2793704},
year = {2015}
}
@inproceedings{Le2016,
abstract = {With increasingly large smartphones, it becomes more difficult to use these devices one-handed. Due to a large touchscreen, users can not reach across the whole screen using their thumb. In this paper, we investigate approaches to move the screen content in order to increase the reachability during one-handed use of large smartphones. In a first study, we compare three ap-proaches based on back-of-device (BoD) interaction to move the screen content. We compare the most preferred BoD ap-proach with direct touch on the front and Apple's Reachability feature. We show that direct touch enables faster target selec-tion than the other approaches but does not allow to interact with large parts of the screen. While Reachability is faster com-pared to a BoD screen shift method, only the BoD approach makes the whole front screen accessible.},
address = {New York, New York, USA},
author = {Le, Huy Viet and Bader, Patrick and Kosch, Thomas and Henze, Niels},
booktitle = {Proceedings of the 9th Nordic Conference on Human-Computer Interaction - NordiCHI '16},
doi = {10.1145/2971485.2971562},
file = {:C$\backslash$:/Users/bsteu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Viet Le et al. - Unknown - Investigating Screen Shifting Techniques to Improve One-Handed Smartphone Usage.pdf:pdf},
isbn = {9781450347631},
keywords = {Author Keywords Smartphone,Input devices and strategies (eg,back-of-device,mouse,one-handed use,reachability,touchscreen)},
pages = {1--10},
publisher = {ACM Press},
title = {{Investigating Screen Shifting Techniques to Improve One-Handed Smartphone Usage}},
url = {http://projects.hcilab.org/bod-phone/files/bod-screen-shift.pdf http://dl.acm.org/citation.cfm?doid=2971485.2971562},
year = {2016}
}
@inproceedings{Baudisch2009,
abstract = {In this paper, we explore how to add pointing input capabilities to very small screen devices. On first sight, touchscreens seem to allow for particular compactness, because they integrate input and screen into the same physical space. The opposite is true, however, because the user's fingers occlude contents and prevent precision. We argue that the key to touch-enabling very small devices is to use touch on the device backside. In order to study this, we have created a 2.4" prototype device; we simulate screens smaller than that by masking the screen. We present a user study in which participants completed a pointing task successfully across display sizes when using a back-of device interface. The touchscreen-based control condition (enhanced with the shift technique), in contrast, failed for screen diagonals below 1 inch. We present four form factor concepts based on back-of-device interaction and provide design guidelines extracted from a second user study.},
address = {New York, New York, USA},
author = {Baudisch, Patrick and Chu, Gerry},
booktitle = {Proceedings of the 27th international conference on Human factors in computing systems - CHI 09},
doi = {10.1145/1518701.1518995},
file = {:C$\backslash$:/Users/bsteu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Baudisch, Chu - Unknown - Back-of-Device Interaction Allows Creating Very Small Touch Devices.pdf:pdf},
isbn = {9781605582467},
keywords = {ACM Classification,B 42 Input Output devices Keywords,H52 [Information interfaces and presentation],User Interfaces Input devices and strategies,back-of-device interaction,lucid-Touch,mobile,nanoTouch,pointing blutwurst,touch},
pages = {1923},
publisher = {ACM Press},
title = {{Back-of-device interaction allows creating very small touch devices}},
url = {http://www.itu.dk/{~}tped/teaching/pervasive/SPCT-F2015/baudisch{\_}and{\_}chu{\_}2009.pdf http://dl.acm.org/citation.cfm?doid=1518701.1518995},
year = {2009}
}
@article{Le2017,
abstract = {Previous research proposed a wide range of interaction methods and use cases based on the previously unused back side and edge of a smartphone. Common approaches to implementing Back-of-Device (BoD) interaction include attaching two smartphones back to back and building a prototype completely from scratch. Changes in the device's form factor can influence hand grip and input performance as shown in previous work. Further, the lack of an established operating system and SDK requires more effort to implement novel interaction methods. In this work, we present a smartphone prototype that runs Android and has a form factor nearly identical to an off-the-shelf smartphone. It further provides capacitive images of the hand holding the device for use cases such as grip-pattern recognition. We describe technical details and share source files so that others can re-build our prototype. We evaluated the prototype with 8 participants to demonstrate the data that can be retrieved for an exemplary grip classification.},
author = {Le, Huy Viet and Mayer, Sven and Bader, Patrick and Henze, Niels},
doi = {10.1145/3098279.3122143},
file = {:C$\backslash$:/Users/bsteu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Viet Le et al. - Unknown - A Smartphone Prototype for Touch Interaction on the Whole Device Surface.pdf:pdf},
isbn = {9781450350754},
journal = {Proceedings of the 19th International Conference on Human-Computer Interaction with Mobile Devices and Services - MobileHCI '17},
keywords = {Full-touch phone,capacitive,mobile,prototype.},
pages = {1--8},
publisher = {ACM},
title = {{A smartphone prototype for touch interaction on the whole device surface}},
url = {https://doi.org/10.1145/3098279.3122143 http://dl.acm.org/citation.cfm?doid=3098279.3122143},
year = {2017}
}
@inproceedings{Holz2015,
abstract = {Recent mobile phones integrate fingerprint scanners to authenticate users biometrically and replace passwords, making authentication more convenient for users. However, due to their cost, capacitive fingerprint scanners have been limited to top-of-the-line phones, a result of the required resolution and quality of the sensor. We present Bodyprint, a biometric authentication system that detects users' bio-metric features using the same type of capacitive sensing, but uses the touchscreen as the image sensor instead. While the input resolution of a touchscreen is {\~{}}6 dpi, the surface area is larger, allowing the touch sensor to scan users' body parts, such as ears, fingers, fists, and palms by pressing them against the display. Bodyprint compensates for the low input resolution with an increased false rejection rate, but does not compromise on authentication precision: In our evaluation with 12 participants, Bodyprint classified body parts with 99.98{\%} accuracy and identifies users with 99.52{\%} accuracy with a false rejection rate of 26.82{\%} to prevent false positives, thereby bringing reliable biometric user authentication to a vast number of commodity devices.},
author = {Holz, Christian and Buthpitiya, Senaka and Knaust, Marius},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems - CHI '15},
doi = {10.1145/2702123.2702518},
isbn = {9781450331456},
issn = {0376-8716},
pages = {3011--3014},
title = {{Bodyprint}},
url = {http://dx.doi.org/10.1145/2702123.2702518 http://dl.acm.org/citation.cfm?doid=2702123.2702518},
year = {2015}
}
@inproceedings{Guo2015,
abstract = {User identification and differentiation have implications in many application domains, including security, personaliza-tion, and co-located multiuser systems. In response, dozens of approaches have been developed, from fingerprint and retinal scans, to hand gestures and RFID tags. In this work, we propose CapAuth, a technique that uses existing, low-level touchscreen data, combined with machine learning classifiers, to provide real-time authentication and even identification of users. As a proof-of-concept, we ran our software on an off-the-shelf Nexus 5 smartphone. Our user study demonstrates twenty-participant authentication accuracies of 99.6{\%}. For twenty-user identification, our software achieved 94.0{\%} accuracy and 98.2{\%} on groups of four, simulating family use.},
author = {Guo, Anhong and Xiao, Robert and Harrison, Chris},
booktitle = {Proceedings of the 2015 International Conference on Interactive Tabletops {\&} Surfaces - ITS '15},
doi = {10.1145/2817721.2817722},
isbn = {9781450338998},
keywords = {Author)Keywords) Touchscreen input,HCI): User Interfaces: Input devices and strategie,capacitive sensing,groupware ACM)Classification)Keywords) H52 Informa,mobile devices,user differentiation,user identification},
mendeley-groups = {Fapra},
pages = {59--62},
title = {{CapAuth}},
url = {http://dx.doi.org/10.1145/2817721.2817722 http://dl.acm.org/citation.cfm?doid=2817721.2817722},
year = {2015}
}
@article{Faizuddin2014,
abstract = {We demonstrate that front-of-screen targeting on mobile phones can be predicted from back-of-device grip manipulations. Using simple, low-resolution capacitive touch sensors placed around a standard phone, we outline a machine learning approach to modelling the grip modulation and inferring front-of-screen touch targets. We experimentally demonstrate that grip is a remarkably good predictor of touch, and we can predict touch position 200ms before contact with an accuracy of 18mm.},
author = {Faizuddin, Mohammad and Noor, Mohd and Ramsay, Andrew and Hughes, Stephen and Rogers, Simon and Williamson, John and Murray-smith, Roderick},
doi = {10.1145/2556288.2557148},
file = {:C$\backslash$:/Users/bsteu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Faizuddin et al. - Unknown - 28 Frames Later Predicting Screen Touches From Back-of-Device Grip Changes.pdf:pdf},
isbn = {9781450324731},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
keywords = {SIGCHI,archival format,proceedings},
mendeley-groups = {Bachelorarbeit,Fapra},
pages = {2005--2008},
title = {{28 Frames Later : Predicting Screen Touches From Back-of-Device Grip Changes}},
url = {http://delivery.acm.org/10.1145/2560000/2557148/p2005-mohdnoor.pdf?ip=141.58.53.227{\&}id=2557148{\&}acc=ACTIVE SERVICE{\&}key=2BA2C432AB83DA15.B24C68F3238D7605.4D4702B0C3E38B35.4D4702B0C3E38B35{\&}{\_}{\_}acm{\_}{\_}=1526556260{\_}b3cb2915bcb45651359cc1eb735a23d6},
year = {2014}
}
@inproceedings{Le2017:Predic,
abstract = {Touchscreens are the dominant input mechanism for a variety of devices. One of the main limitations of touchscreens is the latency to receive input, refresh, and respond. This latency is easily perceivable and reduces users' performance. Previous work proposed to reduce latency by extrapolating finger movements to identify future movements-albeit with limited success. In this paper, we propose PredicTouch, a system that improves this extrapolation using inertial measurement units (IMUs). We combine IMU data with users' touch trajectories to train a multi-layer feedforward neural network that predicts future trajectories. We found that this hybrid approach (soft-ware: prediction, and hardware: IMU) can significantly reduce the prediction error, reducing latency effects. We show that using a wrist-worn IMU increases the throughput by 15{\%} for finger input and 17{\%} for a stylus.},
author = {Le, Huy Viet and Schwind, Valentin and G{\"{o}}ttlich, Philipp and Henze, Niels},
booktitle = {Proceedings of the Interactive Surfaces and Spaces on ZZZ - ISS '17},
doi = {10.1145/3132272.3134138},
isbn = {9781450346917},
keywords = {IMU,Latency,lag,neural network.,prediction,touch input},
mendeley-groups = {Fapra},
pages = {230--239},
title = {{PredicTouch}},
url = {https://doi.org/10.1145/3132272.3134138 http://dl.acm.org/citation.cfm?doid=3132272.3134138},
year = {2017}
}
@inproceedings{MohdNoor2016,
abstract = {We show that when users make errors on mobile devices they make immediate and distinct physical responses that can be observed with standard sensors. We used three standard cognitive tasks (Flanker, Stroop and SART) to induce errors from 20 participants. Using simple low-resolution capacitive touch sensors placed around a standard mobile device and the built-in accelerometer, we demonstrate that errors can be predicted at low error rates from micro-adjustments to hand grip and movement in the period shortly after swiping the touchscreen. Specifically, when combining features derived from hand grip and movement we obtain a mean AUC of 0.96 (with false accept and reject rates both below 10{\%}). Our results demonstrate that hand grip and movement provide strong and low latency evidence for mistakes. The ability to detect user errors in this way could be a valuable component in future interaction systems, allowing interfaces to make it easier for users to correct erroneous inputs.},
address = {New York, New York, USA},
author = {{Mohd Noor}, Mohammad Faizuddin and Rogers, Simon and Williamson, John},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems - CHI '16},
doi = {10.1145/2858036.2858474},
isbn = {9781450333627},
keywords = {accelerometer,back-of-device,capacitive,machine learning,touch},
mendeley-groups = {Bachelorarbeit,Fapra},
pages = {1909--1920},
publisher = {ACM Press},
title = {{Detecting Swipe Errors on Touchscreens using Grip Modulation}},
url = {http://dl.acm.org/citation.cfm?doid=2858036.2858474},
year = {2016}
}
@inproceedings{Lochtefeld2015,
abstract = {Often, we operate mobile devices using only one hand. The hand thereby serves two purposes: holding the device and operating the touch screen with the thumb. The current trend of increasing screen sizes however, makes it close to impossible to reach all parts of the screen (especially the top area) for users with average hand sizes. One solution is to offer adaptive user interfaces for such one-handed interactions. These modes have to be triggered manually and thus induce a critical overhead. They are further designed to bring all content closer, regardless of whether the phone is operated with the left or right hand. In this paper, we present an algorithm that allows determining the users' interacting hand from their unlocking behavior. Our algorithm correctly distinguishes one- and two-handed usage as well as left- and right handed unlocking in 98.51{\%} of all cases. This is achieved through a k-nearest neighbor comparison of the internal sensor readings of the smartphone during the unlocking process.},
address = {New York, New York, USA},
author = {L{\"{o}}chtefeld, Markus and Schardt, Phillip and Kr{\"{u}}ger, Antonio and Boring, Sebastian},
booktitle = {Proceedings of the 14th International Conference on Mobile and Ubiquitous Multimedia - MUM '15},
doi = {10.1145/2836041.2836066},
isbn = {9781450336055},
keywords = {adaptive interfaces,ergonomics,handedness,sensor fusion,unlocking},
mendeley-groups = {Fapra},
pages = {245--249},
publisher = {ACM Press},
title = {{Detecting users handedness for ergonomic adaptation of mobile user interfaces}},
url = {http://dl.acm.org/citation.cfm?doid=2836041.2836066},
year = {2015}
}

