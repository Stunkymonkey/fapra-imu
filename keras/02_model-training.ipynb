{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Importing matplotlib to plot images.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing SK-learn to calculate precision and recall\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneGroupOut\n",
    "from sklearn.utils import shuffle \n",
    "\n",
    "# Used for graph export\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras import backend as K\n",
    "\n",
    "import pickle as pkl\n",
    "import h5py\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import sys\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "# config = tf.ConfigProto(device_count = {\"GPU\": 0})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "# Limit the maximum memory used\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "\n",
    "# set session config\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "smartphones = [\"N5X\"]\n",
    "# TODO remove\n",
    "participants = list(range(1, 4))\n",
    "window_size = 20\n",
    "constant_pixels = 0.06\n",
    "HDF5_PATH = str(Path.home())+\"/data/hdf/\"+smartphones[0]+\"-win\"+str(window_size)+\".hdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H5DF files contains 3 members: labels, segments, groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(343296, 20, 18, 1) (343296, 2) (154389, 20, 18, 1) (154389, 2)\n"
     ]
    }
   ],
   "source": [
    "hdf = h5py.File(HDF5_PATH, \"r\")\n",
    "\n",
    "train_x = hdf[\"train/sensors\"]\n",
    "train_y = hdf[\"train/labels\"]\n",
    "\n",
    "test_x = hdf[\"test/sensors\"]\n",
    "test_y = hdf[\"test/labels\"]\n",
    "\n",
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myGenerator(set_name, batch_size):\n",
    "    \"\"\"\n",
    "    This generator returns images\n",
    "    \"\"\"\n",
    "    hdf = h5py.File(HDF5_PATH, \"r\")\n",
    "\n",
    "    pImages = hdf[set_name + \"/sensors\"]\n",
    "    pLabels = hdf[set_name + \"/labels\"]\n",
    "\n",
    "    len_train = pImages.shape[0]\n",
    "    \n",
    "    randomBatchOrder = np.arange(len_train // batch_size)\n",
    "       \n",
    "    while True:\n",
    "        np.random.shuffle(randomBatchOrder) \n",
    "        \n",
    "        for i in range(len_train // batch_size):\n",
    "            idx = randomBatchOrder[i]\n",
    "            shuffled = shuffle(pImages[idx * batch_size: (idx+1) * batch_size], pLabels[idx * batch_size: (idx+1) * batch_size])\n",
    "            yield shuffled[0].reshape(-1, 1, 20, 18, 1), shuffled[1].reshape(-1, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training- & Test-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ConvLSTM net hyperparameters\n",
    "numChannels = 1\n",
    "numFilters = 128 # number of filters in Conv2D layer\n",
    "# kernal size of the Conv2D layer\n",
    "kernalSize1 = (3,3)\n",
    "# max pooling window size\n",
    "poolingWindowSz = 2\n",
    "# number of filters in fully connected layers\n",
    "numNueronsFCL1 = 512\n",
    "numNueronsFCL2 = 128\n",
    "# number of epochs\n",
    "epochs = 9999\n",
    "# batchsize\n",
    "batch_size = 100\n",
    "# number of total clases\n",
    "numClasses = train_y.shape[1]\n",
    "# dropout ratio for dropout layer\n",
    "dropOutRatio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d_4 (ConvLSTM2D)  (None, None, 20, 18, 128) 594944    \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, None, 10, 9, 128)  0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, None, 10, 9, 128)  0         \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, None, 11520)       0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, None, 512)         5898752   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, None, 128)         65664     \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, None, 2)           258       \n",
      "=================================================================\n",
      "Total params: 6,559,618\n",
      "Trainable params: 6,559,618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/9999\n",
      "3032/3432 [=========================>....] - ETA: 30s - loss: 454.8657 - eucInMM: 38.5966 - rmse: 454.8657 - euc: 643.2772"
     ]
    }
   ],
   "source": [
    "tf.get_default_graph()\n",
    "\n",
    "model = None\n",
    "model = Sequential()\n",
    "# adding the first convLSTM layer with 32 filters and 5 by 5 kernal size, using the rectifier as the activation function\n",
    "model.add(ConvLSTM2D(numFilters, kernalSize1 ,input_shape=(None, train_x.shape[1], train_x.shape[2], 1),activation='relu', padding='same',return_sequences=True))\n",
    "\n",
    "## adding a maxpooling layer\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(poolingWindowSz,poolingWindowSz),padding='valid')))\n",
    "\n",
    "## adding a dropout layer for the regularization and avoiding over fitting\n",
    "model.add(Dropout(dropOutRatio))\n",
    "\n",
    "## flattening the output in order to apple dense layer\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "## adding first fully connected layer with 256 outputs\n",
    "model.add(Dense(numNueronsFCL1, activation='relu'))\n",
    "\n",
    "## adding second fully connected layer 128 outputs\n",
    "model.add(Dense(numNueronsFCL2, activation='relu'))\n",
    "\n",
    "## flattening the output in order to apply the fully connected layer\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "## adding softmax layer for the classification\n",
    "model.add(Dense(numClasses))\n",
    "\n",
    "## Compiling the model to generate a model\n",
    "def eucInMM(y_true, y_pred):\n",
    "    return (K.sqrt(K.sum(K.square(y_true - y_pred), axis=-1, keepdims=True))) * constant_pixels\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
    "\n",
    "def euc(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(y_true - y_pred), axis=-1, keepdims=True))\n",
    "\n",
    "#optimizer = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#optimizer = optimizers.Adam(lr = 0.001, decay=1e-6)\n",
    "optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.1)\n",
    "model.compile(loss=rmse, optimizer=optimizer, metrics=[eucInMM ,rmse, euc])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Broadcast progress to the tensorboard. \n",
    "readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "tensorflowFolder = \"/srv/share/tensorboardfiles/IMU_B(\" + str(batch_size)+ \")_K\" + str(kernalSize1)+\"_\" + smartphones[0] + \"_\" + readable_timestamp\n",
    "#change update_freq to 'batch', 'epoch', int x  (every x samples)\n",
    "tfbCallback = TensorBoard(log_dir=tensorflowFolder, histogram_freq=1,  \n",
    "          write_graph=True, write_images=True, update_freq = 'epoch')\n",
    "\n",
    "history = model.fit_generator(myGenerator(\"train\", batch_size),\n",
    "                    steps_per_epoch=len(train_x) // batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=myGenerator(\"test\", batch_size),\n",
    "                    validation_steps=len(test_x) // batch_size,\n",
    "                    callbacks=[tfbCallback])\n",
    "\n",
    "score = model.evaluate(np.expand_dims(testX,1),np.expand_dims(testY,1),verbose=2)\n",
    "print('%s: %.2f' % (model.metrics_names[1], score[1]))\n",
    "print('Baseline ConvLSTM Error: %.2f' %(1 - score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
