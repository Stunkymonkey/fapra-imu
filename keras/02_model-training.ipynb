{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Importing matplotlib to plot images.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing SK-learn to calculate precision and recall\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneGroupOut\n",
    "\n",
    "# Used for graph export\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras import backend as K\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "# config = tf.ConfigProto(device_count = {\"GPU\": 0})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "# Limit the maximum memory used\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "\n",
    "# set session config\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = list(range(1, 21))\n",
    "smartphones = [\"N5X\"]\n",
    "# TODO remove\n",
    "participants = list(range(1, 4))\n",
    "window_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = list()\n",
    "labels = list()\n",
    "groups = list()\n",
    "\n",
    "for pid in participants:\n",
    "    for smartphone in smartphones:\n",
    "        data = pkl.load(open(str(Path.home()) + \"/data/pickles/fapra_imu-processed-\" +  str(pid) + \"-\" + smartphone + \".pkl\", \"rb\"))\n",
    "        points = data[0]\n",
    "        intervals = data[1]\n",
    "        # split the points to according group\n",
    "        cross = points[:,:2]\n",
    "        pressed = points[:,2:]\n",
    "        \n",
    "        # iterate over intervals\n",
    "        for i, c in zip(intervals, pressed):\n",
    "            samples_per_interval = len(i[0]) - (window_size - 1)\n",
    "            # create array of same label\n",
    "            tmp_labels = [c] * samples_per_interval\n",
    "            tmp_labels = np.array(tmp_labels)\n",
    "            labels.append(tmp_labels)\n",
    "            tmp_groups = [pid] * samples_per_interval\n",
    "            groups = groups + tmp_groups\n",
    "            for k in range(len(i.T[(window_size - 1):])):\n",
    "                chunk = np.array(i.T[k:(k + window_size)])\n",
    "                segments.append(chunk)\n",
    "\n",
    "# make numpy arrays of it\n",
    "labels = np.concatenate(np.array(labels))\n",
    "segments = np.array(segments)\n",
    "groups = np.array(groups, dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1021339, 2)\n",
      "(1021339, 20, 18)\n",
      "(1021339,)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)\n",
    "print(segments.shape)\n",
    "print(groups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining parameters for the input and network layers\n",
    "## we are treating each segmeent or chunk as a 2D image (90 X 18)\n",
    "numOfRows = segments.shape[1]\n",
    "numOfColumns = segments.shape[2]\n",
    "\n",
    "## reshaping the data for network input\n",
    "reshapedSegments = segments.reshape(segments.shape[0], numOfRows, numOfColumns,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training- & Test-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(segments, labels, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ConvLSTM net hyperparameters\n",
    "numChannels = 1\n",
    "numFilters = 128 # number of filters in Conv2D layer\n",
    "# kernal size of the Conv2D layer\n",
    "kernalSize1 = 2\n",
    "# max pooling window size\n",
    "poolingWindowSz = 2\n",
    "# number of filters in fully connected layers\n",
    "numNueronsFCL1 = 128\n",
    "numNueronsFCL2 = 128\n",
    "# number of epochs\n",
    "Epochs = 10\n",
    "# batchsize\n",
    "batchSize = 10\n",
    "# number of total clases\n",
    "numClasses = labels.shape[1]\n",
    "# dropout ratio for dropout layer\n",
    "dropOutRatio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, None, 20, 18, 128) 264704    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 10, 9, 128)  0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 10, 9, 128)  0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, None, 11520)       0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 128)         1474688   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, None, 128)         16512     \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, None, 2)           258       \n",
      "=================================================================\n",
      "Total params: 1,756,162\n",
      "Trainable params: 1,756,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 679200 samples, validate on 342139 samples\n",
      "Epoch 1/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2418 - rmse: 0.2418 - euc: 0.3420 - val_loss: 0.2727 - val_rmse: 0.2727 - val_euc: 0.3857\n",
      "Epoch 2/9999\n",
      "679200/679200 [==============================] - 344s 506us/step - loss: 0.2380 - rmse: 0.2380 - euc: 0.3366 - val_loss: 0.2740 - val_rmse: 0.2740 - val_euc: 0.3875\n",
      "Epoch 3/9999\n",
      "679200/679200 [==============================] - 344s 507us/step - loss: 0.2358 - rmse: 0.2358 - euc: 0.3334 - val_loss: 0.2914 - val_rmse: 0.2914 - val_euc: 0.4121\n",
      "Epoch 4/9999\n",
      "679200/679200 [==============================] - 344s 507us/step - loss: 0.2340 - rmse: 0.2340 - euc: 0.3309 - val_loss: 0.2826 - val_rmse: 0.2826 - val_euc: 0.3997\n",
      "Epoch 5/9999\n",
      "679200/679200 [==============================] - 344s 507us/step - loss: 0.2325 - rmse: 0.2325 - euc: 0.3288 - val_loss: 0.2861 - val_rmse: 0.2861 - val_euc: 0.4046\n",
      "Epoch 6/9999\n",
      "679200/679200 [==============================] - 347s 511us/step - loss: 0.2310 - rmse: 0.2310 - euc: 0.3267 - val_loss: 0.2924 - val_rmse: 0.2924 - val_euc: 0.4135\n",
      "Epoch 7/9999\n",
      "412000/679200 [=================>............] - ETA: 1:54 - loss: 0.2299 - rmse: 0.2299 - euc: 0.3251"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2283 - rmse: 0.2283 - euc: 0.3229 - val_loss: 0.2816 - val_rmse: 0.2816 - val_euc: 0.3983\n",
      "Epoch 9/9999\n",
      " 25700/679200 [>.............................] - ETA: 4:41 - loss: 0.2268 - rmse: 0.2268 - euc: 0.3208"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2271 - rmse: 0.2271 - euc: 0.3211 - val_loss: 0.2840 - val_rmse: 0.2840 - val_euc: 0.4017\n",
      "Epoch 10/9999\n",
      "377600/679200 [===============>..............] - ETA: 2:09 - loss: 0.2261 - rmse: 0.2261 - euc: 0.3197"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "655900/679200 [===========================>..] - ETA: 10s - loss: 0.2247 - rmse: 0.2247 - euc: 0.3178"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2236 - rmse: 0.2236 - euc: 0.3162 - val_loss: 0.2818 - val_rmse: 0.2818 - val_euc: 0.3986\n",
      "Epoch 13/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2226 - rmse: 0.2226 - euc: 0.3148 - val_loss: 0.2843 - val_rmse: 0.2843 - val_euc: 0.4020\n",
      "Epoch 14/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2215 - rmse: 0.2215 - euc: 0.3133 - val_loss: 0.2860 - val_rmse: 0.2860 - val_euc: 0.4044\n",
      "Epoch 15/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2205 - rmse: 0.2205 - euc: 0.3118 - val_loss: 0.2831 - val_rmse: 0.2831 - val_euc: 0.4003\n",
      "Epoch 16/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2196 - rmse: 0.2196 - euc: 0.3105 - val_loss: 0.2799 - val_rmse: 0.2799 - val_euc: 0.3958\n",
      "Epoch 17/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2186 - rmse: 0.2186 - euc: 0.3092 - val_loss: 0.2944 - val_rmse: 0.2944 - val_euc: 0.4163\n",
      "Epoch 18/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2178 - rmse: 0.2178 - euc: 0.3080 - val_loss: 0.2824 - val_rmse: 0.2824 - val_euc: 0.3993\n",
      "Epoch 19/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2169 - rmse: 0.2169 - euc: 0.3067 - val_loss: 0.2804 - val_rmse: 0.2804 - val_euc: 0.3965\n",
      "Epoch 20/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2161 - rmse: 0.2161 - euc: 0.3056 - val_loss: 0.2874 - val_rmse: 0.2874 - val_euc: 0.4064\n",
      "Epoch 21/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2153 - rmse: 0.2153 - euc: 0.3045 - val_loss: 0.2843 - val_rmse: 0.2843 - val_euc: 0.4021\n",
      "Epoch 22/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2145 - rmse: 0.2145 - euc: 0.3034 - val_loss: 0.2928 - val_rmse: 0.2928 - val_euc: 0.4141\n",
      "Epoch 23/9999\n",
      "679200/679200 [==============================] - 346s 509us/step - loss: 0.2137 - rmse: 0.2137 - euc: 0.3022 - val_loss: 0.2895 - val_rmse: 0.2895 - val_euc: 0.4094\n",
      "Epoch 24/9999\n",
      "679200/679200 [==============================] - 345s 509us/step - loss: 0.2130 - rmse: 0.2130 - euc: 0.3012 - val_loss: 0.2961 - val_rmse: 0.2961 - val_euc: 0.4188\n",
      "Epoch 25/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2124 - rmse: 0.2124 - euc: 0.3004 - val_loss: 0.2896 - val_rmse: 0.2896 - val_euc: 0.4095\n",
      "Epoch 26/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2117 - rmse: 0.2117 - euc: 0.2994 - val_loss: 0.2971 - val_rmse: 0.2971 - val_euc: 0.4202\n",
      "Epoch 27/9999\n",
      "679200/679200 [==============================] - 345s 507us/step - loss: 0.2109 - rmse: 0.2109 - euc: 0.2983 - val_loss: 0.2845 - val_rmse: 0.2845 - val_euc: 0.4023\n",
      "Epoch 28/9999\n",
      "679200/679200 [==============================] - 345s 507us/step - loss: 0.2103 - rmse: 0.2103 - euc: 0.2974 - val_loss: 0.2925 - val_rmse: 0.2925 - val_euc: 0.4136\n",
      "Epoch 29/9999\n",
      "679200/679200 [==============================] - 344s 507us/step - loss: 0.2097 - rmse: 0.2097 - euc: 0.2965 - val_loss: 0.2936 - val_rmse: 0.2936 - val_euc: 0.4153\n",
      "Epoch 30/9999\n",
      "679200/679200 [==============================] - 345s 507us/step - loss: 0.2091 - rmse: 0.2091 - euc: 0.2957 - val_loss: 0.2912 - val_rmse: 0.2912 - val_euc: 0.4118\n",
      "Epoch 31/9999\n",
      "679200/679200 [==============================] - 345s 507us/step - loss: 0.2086 - rmse: 0.2086 - euc: 0.2950 - val_loss: 0.2890 - val_rmse: 0.2890 - val_euc: 0.4087\n",
      "Epoch 32/9999\n",
      "679200/679200 [==============================] - 345s 507us/step - loss: 0.2079 - rmse: 0.2079 - euc: 0.2940 - val_loss: 0.2929 - val_rmse: 0.2929 - val_euc: 0.4142\n",
      "Epoch 33/9999\n",
      "679200/679200 [==============================] - 345s 507us/step - loss: 0.2074 - rmse: 0.2074 - euc: 0.2933 - val_loss: 0.2928 - val_rmse: 0.2928 - val_euc: 0.4142\n",
      "Epoch 34/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2070 - rmse: 0.2070 - euc: 0.2927 - val_loss: 0.2929 - val_rmse: 0.2929 - val_euc: 0.4143\n",
      "Epoch 35/9999\n",
      "679200/679200 [==============================] - 345s 507us/step - loss: 0.2064 - rmse: 0.2064 - euc: 0.2918 - val_loss: 0.2883 - val_rmse: 0.2883 - val_euc: 0.4077\n",
      "Epoch 36/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2058 - rmse: 0.2058 - euc: 0.2911 - val_loss: 0.2925 - val_rmse: 0.2925 - val_euc: 0.4137\n",
      "Epoch 37/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2053 - rmse: 0.2053 - euc: 0.2904 - val_loss: 0.2941 - val_rmse: 0.2941 - val_euc: 0.4159\n",
      "Epoch 38/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2050 - rmse: 0.2050 - euc: 0.2899 - val_loss: 0.2924 - val_rmse: 0.2924 - val_euc: 0.4135\n",
      "Epoch 39/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2045 - rmse: 0.2045 - euc: 0.2893 - val_loss: 0.2907 - val_rmse: 0.2907 - val_euc: 0.4111\n",
      "Epoch 40/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2041 - rmse: 0.2041 - euc: 0.2886 - val_loss: 0.2931 - val_rmse: 0.2931 - val_euc: 0.4145\n",
      "Epoch 41/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2036 - rmse: 0.2036 - euc: 0.2880 - val_loss: 0.2935 - val_rmse: 0.2935 - val_euc: 0.4150\n",
      "Epoch 42/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2033 - rmse: 0.2033 - euc: 0.2874 - val_loss: 0.3006 - val_rmse: 0.3006 - val_euc: 0.4252\n",
      "Epoch 43/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2028 - rmse: 0.2028 - euc: 0.2869 - val_loss: 0.2935 - val_rmse: 0.2935 - val_euc: 0.4150\n",
      "Epoch 44/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2025 - rmse: 0.2025 - euc: 0.2864 - val_loss: 0.2943 - val_rmse: 0.2943 - val_euc: 0.4162\n",
      "Epoch 45/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2021 - rmse: 0.2021 - euc: 0.2858 - val_loss: 0.2992 - val_rmse: 0.2992 - val_euc: 0.4231\n",
      "Epoch 46/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2017 - rmse: 0.2017 - euc: 0.2853 - val_loss: 0.2965 - val_rmse: 0.2965 - val_euc: 0.4193\n",
      "Epoch 47/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2013 - rmse: 0.2013 - euc: 0.2847 - val_loss: 0.2990 - val_rmse: 0.2990 - val_euc: 0.4228\n",
      "Epoch 48/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2010 - rmse: 0.2010 - euc: 0.2843 - val_loss: 0.2998 - val_rmse: 0.2998 - val_euc: 0.4240\n",
      "Epoch 49/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2007 - rmse: 0.2007 - euc: 0.2839 - val_loss: 0.2982 - val_rmse: 0.2982 - val_euc: 0.4218\n",
      "Epoch 50/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2004 - rmse: 0.2004 - euc: 0.2834 - val_loss: 0.2992 - val_rmse: 0.2992 - val_euc: 0.4232\n",
      "Epoch 51/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.2000 - rmse: 0.2000 - euc: 0.2828 - val_loss: 0.3022 - val_rmse: 0.3022 - val_euc: 0.4274\n",
      "Epoch 52/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.1997 - rmse: 0.1997 - euc: 0.2825 - val_loss: 0.2965 - val_rmse: 0.2965 - val_euc: 0.4193\n",
      "Epoch 53/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.1994 - rmse: 0.1994 - euc: 0.2820 - val_loss: 0.2963 - val_rmse: 0.2963 - val_euc: 0.4190\n",
      "Epoch 54/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.1990 - rmse: 0.1990 - euc: 0.2815 - val_loss: 0.2975 - val_rmse: 0.2975 - val_euc: 0.4207\n",
      "Epoch 55/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.1988 - rmse: 0.1988 - euc: 0.2811 - val_loss: 0.2983 - val_rmse: 0.2983 - val_euc: 0.4219\n",
      "Epoch 56/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.1985 - rmse: 0.1985 - euc: 0.2807 - val_loss: 0.3041 - val_rmse: 0.3041 - val_euc: 0.4301\n",
      "Epoch 57/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.1982 - rmse: 0.1982 - euc: 0.2802 - val_loss: 0.3006 - val_rmse: 0.3006 - val_euc: 0.4251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.1979 - rmse: 0.1979 - euc: 0.2799 - val_loss: 0.2956 - val_rmse: 0.2956 - val_euc: 0.4181\n",
      "Epoch 59/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.1977 - rmse: 0.1977 - euc: 0.2796 - val_loss: 0.2916 - val_rmse: 0.2916 - val_euc: 0.4124\n",
      "Epoch 60/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.1974 - rmse: 0.1974 - euc: 0.2791 - val_loss: 0.3018 - val_rmse: 0.3018 - val_euc: 0.4268\n",
      "Epoch 61/9999\n",
      "679200/679200 [==============================] - 345s 508us/step - loss: 0.1972 - rmse: 0.1972 - euc: 0.2789 - val_loss: 0.2974 - val_rmse: 0.2974 - val_euc: 0.4205\n",
      "Epoch 62/9999\n",
      "679100/679200 [============================>.] - ETA: 0s - loss: 0.1969 - rmse: 0.1969 - euc: 0.2784"
     ]
    }
   ],
   "source": [
    "tf.get_default_graph()\n",
    "for index, (train_index, test_index) in enumerate(logo.split(reshapedSegments, labels, groups)):\n",
    "\n",
    "    # print('TRAIN:', train_index, 'TEST:', test_index)\n",
    "    trainX, testX = reshapedSegments[train_index], reshapedSegments[test_index]\n",
    "    trainY, testY = labels[train_index], labels[test_index]\n",
    "    \n",
    "    model = None\n",
    "    model = Sequential()\n",
    "    # adding the first convLSTM layer with 32 filters and 5 by 5 kernal size, using the rectifier as the activation function\n",
    "    model.add(ConvLSTM2D(numFilters, (kernalSize1,kernalSize1),input_shape=(None, numOfRows, numOfColumns, 1),activation='relu', padding='same',return_sequences=True))\n",
    "\n",
    "    ## adding a maxpooling layer\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(poolingWindowSz,poolingWindowSz),padding='valid')))\n",
    "\n",
    "    ## adding a dropout layer for the regularization and avoiding over fitting\n",
    "    model.add(Dropout(dropOutRatio))\n",
    "\n",
    "    ## flattening the output in order to apple dense layer\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "    ## adding first fully connected layer with 256 outputs\n",
    "    model.add(Dense(numNueronsFCL1, activation='relu'))\n",
    "\n",
    "    ## adding second fully connected layer 128 outputs\n",
    "    model.add(Dense(numNueronsFCL2, activation='relu'))\n",
    "\n",
    "    ## flattening the output in order to apply the fully connected layer\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "    ## adding softmax layer for the classification\n",
    "    model.add(Dense(numClasses, activation='softmax'))\n",
    "\n",
    "    ## Compiling the model to generate a model\n",
    "    sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    def rmse(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
    "    \n",
    "    def euc(y_true, y_pred):\n",
    "        return K.sqrt(K.sum(K.square(y_true - y_pred), axis=-1, keepdims=True))\n",
    "    \n",
    "    model.compile(loss=rmse, optimizer=sgd, metrics=[rmse,euc])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    history = model.fit(np.expand_dims(trainX,1),np.expand_dims(trainY,1), \n",
    "                        validation_data=(np.expand_dims(testX,1),np.expand_dims(testY,1)),\n",
    "                        epochs=9999,batch_size=100,verbose=1)\n",
    "\n",
    "    score = model.evaluate(np.expand_dims(testX,1),np.expand_dims(testY,1),verbose=2)\n",
    "    print('%s: %.2f' % (model.metrics_names[1], score[1]))\n",
    "    print('Baseline ConvLSTM Error: %.2f' %(1-score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
