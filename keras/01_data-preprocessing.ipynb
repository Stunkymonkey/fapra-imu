{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for file-management\n",
    "import pickle as pkl\n",
    "from pathlib import Path\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Participant Infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = False\n",
    "participants = list(range(1, 21))\n",
    "smartphones = [\"S3Mini\", \"S4\", \"N5X\", \"N6\"]\n",
    "event_time_diff = 3\n",
    "normalize_screen = True\n",
    "\n",
    "sensors = [\n",
    "    \"acc\",\n",
    "    \"gyro\",\n",
    "    \"ori\",\n",
    "    \"grav\",\n",
    "    \"mag\",\n",
    "    \"rot\"\n",
    "]\n",
    "\n",
    "tasks = [\n",
    "    \"points\",\n",
    "    \"fitts\"\n",
    "]\n",
    "\n",
    "file_names = sensors + tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing - participant: 1 smartphone: S3Mini\n",
      "processing - participant: 1 smartphone: S4\n",
      "processing - participant: 1 smartphone: N5X\n",
      "processing - participant: 1 smartphone: N6\n",
      "processing - participant: 2 smartphone: S3Mini\n",
      "processing - participant: 2 smartphone: S4\n",
      "processing - participant: 2 smartphone: N5X\n",
      "processing - participant: 2 smartphone: N6\n",
      "processing - participant: 3 smartphone: S3Mini\n",
      "processing - participant: 3 smartphone: S4\n",
      "processing - participant: 3 smartphone: N5X\n",
      "processing - participant: 3 smartphone: N6\n",
      "processing - participant: 4 smartphone: S3Mini\n",
      "processing - participant: 4 smartphone: S4\n",
      "processing - participant: 4 smartphone: N5X\n",
      "processing - participant: 4 smartphone: N6\n",
      "processing - participant: 5 smartphone: S3Mini\n",
      "processing - participant: 5 smartphone: S4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2102\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_loc\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   2624\u001b[0m                                                       \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2625\u001b[0m                                                       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2626\u001b[0;31m                                                       dtype=new_values.dtype)\n\u001b[0m\u001b[1;32m   2627\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2628\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_validate_dtype\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;31m# a compound dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mpandas_dtype\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m   2022\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'object'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnpdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2024\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mnpdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2025\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dtype {dtype} not understood'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for PID in participants:\n",
    "    for smartphone in smartphones:\n",
    "        print(\"processing - participant:\", str(PID), \"smartphone:\", smartphone)\n",
    "\n",
    "        # set screen resolution\n",
    "        if smartphone == \"N5X\":\n",
    "            pixels = {\"width\": 1080, \"height\": 1920}\n",
    "        elif smartphone == \"S3Mini\":\n",
    "            pixels = {\"width\": 480, \"height\": 800}\n",
    "        elif smartphone == \"S4\":\n",
    "            pixels = {\"width\": 1080, \"height\": 1920}\n",
    "        elif smartphone == \"N6\":\n",
    "            pixels = {\"width\": 1440, \"height\": 2560}\n",
    "\n",
    "        # Read Files\n",
    "        raw_data = dict()\n",
    "\n",
    "        if output: print(\"read files\")\n",
    "        for file in file_names:\n",
    "            file_path = str(Path.home()) + \"/data/raw/fapra_imu-\" +  str(PID) + \"-\" + file + \"-\" + smartphone + \"-0.csv\"\n",
    "            if not os.path.isfile(file_path):\n",
    "                print(file_path + \"not found\")\n",
    "                continue\n",
    "            raw_data[file] = pd.read_csv(file_path, \";\")\n",
    "\n",
    "        # split by time in seperate lists\n",
    "        if output: print(\"sort to specific interval\")\n",
    "        time_filtered_data = dict()\n",
    "        for name in file_names:\n",
    "            tmp = []\n",
    "            for k, end in enumerate(raw_data[\"points\"].time):\n",
    "                start = int(raw_data[\"fitts\"].time[k])\n",
    "                # create mask for time interval\n",
    "                mask = (raw_data[name][\"time\"] > start) & (raw_data[name][\"time\"] <= end)\n",
    "                # only return items matching to mask\n",
    "                tmp.append(raw_data[name].loc[mask])\n",
    "            time_filtered_data[name] = tmp\n",
    "        # list to dataframe\n",
    "        time_filtered_data[\"points\"] = pd.concat(time_filtered_data[\"points\"])\n",
    "\n",
    "        # scale screen\n",
    "        if normalize_screen:\n",
    "            time_filtered_data[\"points\"][\"x-press\"] = time_filtered_data[\"points\"][\"x-press\"].div(pixels[\"width\"])\n",
    "            time_filtered_data[\"points\"][\"x-circle\"] = time_filtered_data[\"points\"][\"x-circle\"].div(pixels[\"width\"])\n",
    "            time_filtered_data[\"points\"][\"y-press\"] = time_filtered_data[\"points\"][\"y-press\"].div(pixels[\"height\"])\n",
    "            time_filtered_data[\"points\"][\"y-circle\"] = time_filtered_data[\"points\"][\"y-circle\"].div(pixels[\"height\"])\n",
    "\n",
    "        # filter unique timestamps\n",
    "        for k, item in enumerate(time_filtered_data[\"points\"]):\n",
    "            for sensor in sensors:\n",
    "                time_filtered_data[sensor][k] = time_filtered_data[sensor][k].drop_duplicates(subset=\"time\", keep=\"last\")\n",
    "        \n",
    "        # Create Array\n",
    "        result_interval = []\n",
    "        if output: print(\"create-interval\", end=' ')\n",
    "        for k, point in time_filtered_data[\"points\"].iterrows():\n",
    "            if output: print(k, end=' ', flush=True)\n",
    "            one_interval = []\n",
    "            interval = dict()\n",
    "            for sensor in sensors:\n",
    "                interval[sensor] = time_filtered_data[sensor][k]\n",
    "\n",
    "            # keeps index of each sensor\n",
    "            position = dict()\n",
    "            # keeps value of last sensor event\n",
    "            last_values = dict()\n",
    "            for sensor in sensors:\n",
    "                position[sensor] = 0\n",
    "                last_values[sensor] = 0\n",
    "\n",
    "            # find maximum first timestamp in all sensors\n",
    "            current_time = -1\n",
    "            for sensor in sensors:\n",
    "                if interval[sensor][\"time\"].iloc[position[sensor]] > current_time:\n",
    "                    current_time = interval[sensor][\"time\"].iloc[position[sensor]]\n",
    "                last_values[sensor] = interval[sensor][:].iloc[position[sensor]]\n",
    "            \n",
    "            # print(\"start\", raw_data[\"fitts\"].time.iloc[k])\n",
    "            # print(\"first_data\", current_time)\n",
    "            # print(\"end\", time_filtered_data[\"points\"].iloc[k][\"time\"])\n",
    "\n",
    "            # iterate as long as time has not reached max\n",
    "            while current_time <= time_filtered_data[\"points\"].iloc[k][\"time\"]:\n",
    "                # iterate over alle sensors to find values before current_time (maybe one sensor is having multiple updates)\n",
    "                while True:\n",
    "                    all_valid = True\n",
    "                    for sensor in sensors:\n",
    "                        if position[sensor] + 1 >= len(interval[sensor][\"time\"]):\n",
    "                            continue\n",
    "                        if interval[sensor][\"time\"].iloc[position[sensor] + 1] <= current_time:\n",
    "                            position[sensor] += 1\n",
    "                            last_values[sensor] = interval[sensor][:].iloc[position[sensor]]\n",
    "                            all_valid = False\n",
    "                    if all_valid:\n",
    "                        break\n",
    "                one_interval.append(last_values.copy())\n",
    "                current_time = current_time + event_time_diff\n",
    "            result_interval.append(one_interval)\n",
    "        \n",
    "        # make numpy arrays (without dicts)\n",
    "        if output: print()\n",
    "        if output: print(\"make numpy-array interval\", end=' ')\n",
    "        final_intervals = []\n",
    "        for k, interval in enumerate(result_interval):\n",
    "            if output: print(k, end=' ', flush=True)\n",
    "            current_interval = []\n",
    "            for i in interval:\n",
    "                event = []\n",
    "                for sensor in i.values():\n",
    "                    # except timestamp\n",
    "                    for value in sensor[1:]:\n",
    "                        event.append(value)\n",
    "                current_interval.append(np.asarray(event))\n",
    "            # make list to array, transpose and make 2d matrix\n",
    "            final_intervals.append(np.array(np.asarray(current_interval).transpose()))\n",
    "        \n",
    "        if output: print()\n",
    "        if output: print(\"make numpy-array points\")\n",
    "        final_points = time_filtered_data[\"points\"][['x-press','y-press','x-circle','y-circle']].values\n",
    "        final_result = [final_points, final_intervals]\n",
    "\n",
    "        # save dump pickles\n",
    "        data_path = str(Path.home()) + \"/data/pickles/fapra_imu-processed-\" +  str(PID) + \"-\" + smartphone + \".pkl\"\n",
    "        pkl.dump(final_result, open( data_path, \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# for file-management\n",
    "import h5py\n",
    "import pickle as pkl\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = True\n",
    "participants = list(range(1, 21))\n",
    "smartphones = [\"S3Mini\", \"S4\", \"N5X\", \"N6\"]\n",
    "train = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "test = [15, 16, 17, 18, 19, 20]\n",
    "window_sizes = [25, 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hdf-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating hdf5 - window_size: 25 smartphone: S3Mini phase: train participant: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \n",
      "creating hdf5 - window_size: 25 smartphone: S3Mini phase: test participant: 15 16 17 18 19 20 \n",
      "creating hdf5 - window_size: 25 smartphone: S4 phase: train participant: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \n",
      "creating hdf5 - window_size: 25 smartphone: S4 phase: test participant: 15 16 17 18 19 20 \n",
      "creating hdf5 - window_size: 25 smartphone: N5X phase: train participant: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \n",
      "creating hdf5 - window_size: 25 smartphone: N5X phase: test participant: 15 16 17 18 19 20 \n",
      "creating hdf5 - window_size: 25 smartphone: N6 phase: train participant: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \n",
      "creating hdf5 - window_size: 25 smartphone: N6 phase: test participant: 15 16 17 18 19 20 \n",
      "creating hdf5 - window_size: 50 smartphone: S3Mini phase: train participant: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \n",
      "creating hdf5 - window_size: 50 smartphone: S3Mini phase: test participant: 15 16 17 18 19 20 \n",
      "creating hdf5 - window_size: 50 smartphone: S4 phase: train participant: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \n",
      "creating hdf5 - window_size: 50 smartphone: S4 phase: test participant: 15 16 17 18 19 20 \n",
      "creating hdf5 - window_size: 50 smartphone: N5X phase: train participant: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \n",
      "creating hdf5 - window_size: 50 smartphone: N5X phase: test participant: 15 16 17 18 19 20 \n",
      "creating hdf5 - window_size: 50 smartphone: N6 phase: train participant: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \n",
      "creating hdf5 - window_size: 50 smartphone: N6 phase: test participant: 15 16 17 18 19 20 \n",
      "CPU times: user 3.39 s, sys: 2.4 s, total: 5.78 s\n",
      "Wall time: 8.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for window_size in window_sizes:\n",
    "    for smartphone in smartphones:\n",
    "        hf = h5py.File(str(Path.home()) + \"/data/hdf-small/\" + smartphone + \"-win\" + str(window_size) + \".hdf\", \"w\")\n",
    "        for phase in [\"train\", \"test\"]:\n",
    "            segments = list()\n",
    "            labels = list()\n",
    "            groups = list()\n",
    "            print(\"creating hdf5 - window_size:\", window_size, \"smartphone:\", smartphone, \"phase:\", phase, end=' ')\n",
    "            if output: print(\"participant:\", end=' ')\n",
    "            current_participants = train if phase is \"train\" else test\n",
    "            for pid in current_participants:\n",
    "                if output: print(pid, end=' ', flush=True)\n",
    "\n",
    "                data = pkl.load(open(str(Path.home()) + \"/data/pickles/fapra_imu-processed-\" +  str(pid) + \"-\" + smartphone + \".pkl\", \"rb\"))\n",
    "                points = data[0]\n",
    "                intervals = data[1]\n",
    "                # split the points to according group\n",
    "                pressed = points[:,:2]\n",
    "                cross = points[:,2:]\n",
    "\n",
    "                # iterate over intervals\n",
    "                for i, c in zip(intervals, pressed):\n",
    "                    samples_per_interval = len(i[0]) - (window_size - 1)\n",
    "                    # create array of same label\n",
    "                    labels.append(np.array([c]))\n",
    "                    chunk = np.array(i.T[len(i.T[(window_size):]):(len(i.T[(window_size - 1):]) + window_size)])\n",
    "                    segments.append(chunk)\n",
    "\n",
    "            # make numpy arrays of it\n",
    "            # wenn window_size größer als intervall ist, dann wirf es ein error\n",
    "            labels = np.concatenate(np.array(labels), axis=0)\n",
    "            segments = np.array(segments)\n",
    "            \n",
    "            segments = segments.reshape(segments.shape[0], segments.shape[1], segments.shape[2], 1)\n",
    "\n",
    "            if phase is \"train\":\n",
    "                hf.create_dataset(\"train/labels\", data=labels)\n",
    "                hf.create_dataset(\"train/sensors\", data=segments)\n",
    "            else:\n",
    "                hf.create_dataset(\"test/labels\", data=labels)\n",
    "                hf.create_dataset(\"test/sensors\", data=segments)\n",
    "            print()\n",
    "        hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hdf-normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating hdf5 - window_size: 25 smartphone: S3Mini phase: train participant: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \n",
      "creating hdf5 - window_size: 25 smartphone: S3Mini phase: test participant: 15 16 17 18 19 20 \n",
      "creating hdf5 - window_size: 25 smartphone: S4 phase: train participant: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \n",
      "creating hdf5 - window_size: 25 smartphone: S4 phase: test participant: 15 16 17 18 19 20 \n",
      "creating hdf5 - window_size: 25 smartphone: N5X phase: train participant: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \n",
      "creating hdf5 - window_size: 25 smartphone: N5X phase: test participant: 15 16 17 18 19 20 \n",
      "creating hdf5 - window_size: 25 smartphone: N6 phase: train participant: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \n",
      "creating hdf5 - window_size: 25 smartphone: N6 phase: test participant: 15 16 17 18 19 20 \n",
      "creating hdf5 - window_size: 50 smartphone: S3Mini phase: train participant: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \n",
      "creating hdf5 - window_size: 50 smartphone: S3Mini phase: test participant: 15 16 17 18 19 20 \n",
      "creating hdf5 - window_size: 50 smartphone: S4 phase: train participant: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \n",
      "creating hdf5 - window_size: 50 smartphone: S4 phase: test participant: 15 16 17 18 19 20 \n",
      "creating hdf5 - window_size: 50 smartphone: N5X phase: train participant: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \n",
      "creating hdf5 - window_size: 50 smartphone: N5X phase: test participant: 15 16 17 18 19 20 \n",
      "creating hdf5 - window_size: 50 smartphone: N6 phase: train participant: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \n",
      "creating hdf5 - window_size: 50 smartphone: N6 phase: test participant: 15 16 17 18 19 20 \n",
      "CPU times: user 7min 21s, sys: 2min 42s, total: 10min 3s\n",
      "Wall time: 13min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for window_size in window_sizes:\n",
    "    for smartphone in smartphones:\n",
    "        hf = h5py.File(str(Path.home()) + \"/data/hdf/\" + smartphone + \"-win\" + str(window_size) + \".hdf\", \"w\")\n",
    "        for phase in [\"train\", \"test\"]:\n",
    "            segments = list()\n",
    "            labels = list()\n",
    "            groups = list()\n",
    "            print(\"creating hdf5 - window_size:\", window_size, \"smartphone:\", smartphone, \"phase:\", phase, end=' ')\n",
    "            if output: print(\"participant:\", end=' ')\n",
    "            current_participants = train if phase is \"train\" else test\n",
    "            for pid in current_participants:\n",
    "                if output: print(pid, end=' ', flush=True)\n",
    "\n",
    "                data = pkl.load(open(str(Path.home()) + \"/data/pickles/fapra_imu-processed-\" +  str(pid) + \"-\" + smartphone + \".pkl\", \"rb\"))\n",
    "                points = data[0]\n",
    "                intervals = data[1]\n",
    "                # split the points to according group\n",
    "                pressed = points[:,:2]\n",
    "                cross = points[:,2:]\n",
    "\n",
    "                # iterate over intervals\n",
    "                for i, c in zip(intervals, pressed):\n",
    "                    samples_per_interval = len(i[0]) - (window_size - 1)\n",
    "                    # create array of same label\n",
    "                    tmp_labels = [c] * samples_per_interval\n",
    "                    tmp_labels = np.array(tmp_labels)\n",
    "                    labels.append(tmp_labels)\n",
    "                    tmp_groups = [pid] * samples_per_interval\n",
    "                    groups = groups + tmp_groups\n",
    "                    for k in range(len(i.T[(window_size - 1):])):\n",
    "                        chunk = np.array(i.T[k:(k + window_size)])\n",
    "                        segments.append(chunk)\n",
    "\n",
    "            # make numpy arrays of it\n",
    "            # wenn window_size größer als intervall ist, dann wirf es ein error\n",
    "            labels = np.concatenate(np.array(labels), axis=0)\n",
    "            segments = np.array(segments)\n",
    "            groups = np.array(groups, dtype=np.int8)\n",
    "            \n",
    "            segments = segments.reshape(segments.shape[0], segments.shape[1], segments.shape[2], 1)\n",
    "\n",
    "            if phase is \"train\":\n",
    "                hf.create_dataset(\"train/labels\", data=labels)\n",
    "                hf.create_dataset(\"train/sensors\", data=segments)\n",
    "            else:\n",
    "                hf.create_dataset(\"test/labels\", data=labels)\n",
    "                hf.create_dataset(\"test/sensors\", data=segments)\n",
    "            print()\n",
    "        hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
