{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import load_model\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU and CPU settings\n",
    "If GPU is not available, comment out the bottom block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "# config = tf.ConfigProto(device_count = {\"GPU\": 0})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "# Limit the maximum memory used\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "\n",
    "# set session config\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = \"knuckle1000\"\n",
    "\n",
    "input_path = \"./\"\n",
    "input_file = modelname + \".h5\"\n",
    "\n",
    "output_path = \"./\"\n",
    "output_file = modelname + \".pb\"\n",
    "\n",
    "output_node_prefix = \"output_node\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output nodes names are:  ['output_node0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:327: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "K.set_learning_phase(0)\n",
    "net_model = load_model(input_path + input_file)\n",
    "\n",
    "num_output = 1\n",
    "pred = [None]*num_output\n",
    "pred_node_names = [None]*num_output\n",
    "for i in range(num_output):\n",
    "    pred_node_names[i] = output_node_prefix+str(i)\n",
    "    pred[i] = tf.identity(net_model.outputs[i], name=pred_node_names[i])\n",
    "print('output nodes names are: ', pred_node_names)\n",
    "output_node_prefix = pred_node_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 8 variables.\n",
      "Converted 8 variables to const ops.\n",
      "Saved the freezed graph at:  ./knuckle1000.pb\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), pred_node_names)\n",
    "\n",
    "graph_io.write_graph(constant_graph, output_path, output_file, as_text=False)\n",
    "\n",
    "print('Saved the freezed graph at: ', (output_path + output_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show input and output node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_7_input\n",
      "conv2d_7/kernel\n",
      "conv2d_7/kernel/read\n",
      "conv2d_7/bias\n",
      "conv2d_7/bias/read\n",
      "conv2d_7/convolution\n",
      "conv2d_7/BiasAdd\n",
      "conv2d_7/Relu\n",
      "conv2d_8/kernel\n",
      "conv2d_8/kernel/read\n",
      "conv2d_8/bias\n",
      "conv2d_8/bias/read\n",
      "conv2d_8/convolution\n",
      "conv2d_8/BiasAdd\n",
      "conv2d_8/Relu\n",
      "max_pooling2d_4/MaxPool\n",
      "dropout_4/Identity\n",
      "flatten_4/Shape\n",
      "flatten_4/strided_slice/stack\n",
      "flatten_4/strided_slice/stack_1\n",
      "flatten_4/strided_slice/stack_2\n",
      "flatten_4/strided_slice\n",
      "flatten_4/Const\n",
      "flatten_4/Prod\n",
      "flatten_4/stack/0\n",
      "flatten_4/stack\n",
      "flatten_4/Reshape\n",
      "dense_7/kernel\n",
      "dense_7/kernel/read\n",
      "dense_7/bias\n",
      "dense_7/bias/read\n",
      "dense_7/MatMul\n",
      "dense_7/BiasAdd\n",
      "dense_7/Relu\n",
      "dense_8/kernel\n",
      "dense_8/kernel/read\n",
      "dense_8/bias\n",
      "dense_8/bias/read\n",
      "dense_8/MatMul\n",
      "dense_8/BiasAdd\n",
      "dense_8/Softmax\n",
      "output_node0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g = tf.GraphDef()\n",
    "g.ParseFromString(open(output_path + output_file, \"rb\").read())\n",
    "s = \"\"\n",
    "for n in g.node:\n",
    "    s =s + str(n.name) + \"\\n\"\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
